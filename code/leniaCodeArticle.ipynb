{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l6D-g1Q38yyC"
   },
   "source": [
    "# Intro\n",
    "\n",
    "This colab is a demo for the article : https://developmentalsystems.org/sensorimotor-lenia/ . It contains the code of the main method of the blogpost that you can try yourself, as well as demo of creatures and the system.\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "*   Run **Prepare System** before anything else in order to define the system and useful demo codes.  This section contains the code of the system (differentiable Lenia)\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "\n",
    "*   **Random Rules** random samples of parameters\n",
    "*   **Demo Robust creature**  Try yourself the creature found by the method by putting them in an environment with obstacles you can draw yourself.\n",
    "*   **Main** You can try the method yourself to try to get new robust moving creatures. You can either use the seeded run, or use a random seed (but optimization might get stuck and you may have to run it several times). At the end, you can try the creature obtained with obstacles. This section contains the code for the method (IMGEP code)\n",
    "*   **Gecko experiment** Use gradient descent on the parameters of the update rule and on an initialization square to grow a gecko shape from a square.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uDjyEeN-qTwc"
   },
   "source": [
    "# Prepare system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xlygnkPVc8dV"
   },
   "source": [
    "### Import package and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8KJwrXkyV9tj",
    "outputId": "af2fae2c-1a7d-40a4-adea-c972ef260d01"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: torchvision==0.15. in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (0.15.0)\n",
      "Requirement already satisfied: numpy in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torchvision==0.15.) (1.26.4)\n",
      "Requirement already satisfied: requests in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torchvision==0.15.) (2.32.2)\n",
      "Requirement already satisfied: torch==2.0.0 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torchvision==0.15.) (2.0.0)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torchvision==0.15.) (10.3.0)\n",
      "Requirement already satisfied: filelock in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torch==2.0.0->torchvision==0.15.) (3.14.0)\n",
      "Requirement already satisfied: typing-extensions in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torch==2.0.0->torchvision==0.15.) (4.11.0)\n",
      "Requirement already satisfied: sympy in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torch==2.0.0->torchvision==0.15.) (1.12)\n",
      "Requirement already satisfied: networkx in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torch==2.0.0->torchvision==0.15.) (3.3)\n",
      "Requirement already satisfied: jinja2 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from torch==2.0.0->torchvision==0.15.) (3.1.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from requests->torchvision==0.15.) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from requests->torchvision==0.15.) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from requests->torchvision==0.15.) (2.2.1)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from requests->torchvision==0.15.) (2024.2.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from jinja2->torch==2.0.0->torchvision==0.15.) (2.1.5)\n",
      "Requirement already satisfied: mpmath>=0.19 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from sympy->torch==2.0.0->torchvision==0.15.) (1.3.0)\n",
      "Requirement already satisfied: ffmpeg in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (1.4)\n"
     ]
    }
   ],
   "source": [
    "!pip install torchvision==0.15.\n",
    "!pip install ffmpeg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vb_saXcBOckj",
    "outputId": "42d8e4d7-c2d7-48ca-d267-4a2a8038f808"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: addict in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (2.4.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install addict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "RX3ROCLrNw63"
   },
   "outputs": [],
   "source": [
    "from addict import Dict\n",
    "import torch\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import warnings\n",
    "import matplotlib.pyplot as plt\n",
    "import numbers\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from collections import OrderedDict\n",
    "from torchvision.transforms.functional import rotate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "31bsYLW5Q3nO"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['FFMPEG_BINARY'] = 'ffmpeg'\n",
    "import moviepy.editor as mvp\n",
    "from moviepy.video.io.ffmpeg_writer import FFMPEG_VideoWriter\n",
    "from IPython.display import HTML, display, clear_output\n",
    "\n",
    "class VideoWriter:\n",
    "  def __init__(self, filename, fps=30.0, **kw):\n",
    "    self.writer = None\n",
    "    self.params = dict(filename=filename, fps=fps, **kw)\n",
    "\n",
    "  def add(self, img):\n",
    "    img = np.asarray(img)\n",
    "    if self.writer is None:\n",
    "      h, w = img.shape[:2]\n",
    "      self.writer = FFMPEG_VideoWriter(size=(w, h), **self.params)\n",
    "    if img.dtype in [np.float32, np.float64]:\n",
    "      img = np.uint8(img.clip(0, 1)*255)\n",
    "    if len(img.shape) == 2:\n",
    "      img = np.repeat(img[..., None], 3, -1)\n",
    "    self.writer.write_frame(img)\n",
    "\n",
    "  def close(self):\n",
    "    if self.writer:\n",
    "      self.writer.close()\n",
    "\n",
    "  def __enter__(self):\n",
    "    return self\n",
    "\n",
    "  def __exit__(self, *kw):\n",
    "    self.close()\n",
    "\n",
    "  def show(self, **kw):\n",
    "      self.close()\n",
    "      fn = self.params['filename']\n",
    "      display(mvp.ipython_display(fn, **kw))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "GG3xwLPvNzvU"
   },
   "outputs": [],
   "source": [
    "def complex_mult_torch(X, Y):\n",
    "    \"\"\" Computes the complex multiplication in Pytorch when the tensor last dimension is 2: 0 is the real component and 1 the imaginary one\"\"\"\n",
    "    assert X.shape[-1] == 2 and Y.shape[-1] == 2, 'Last dimension must be 2'\n",
    "    return torch.stack(\n",
    "        (X[..., 0] * Y[..., 0] - X[..., 1] * Y[..., 1],\n",
    "         X[..., 0] * Y[..., 1] + X[..., 1] * Y[..., 0]),\n",
    "        dim=-1)\n",
    "\n",
    "\n",
    "def roll_n(X, axis, n):\n",
    "    \"\"\" Rolls a tensor with a shift n on the specified axis\"\"\"\n",
    "    torch.roll(X, n, axis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rknPms1_sIyt"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AkIG0JDXNi7b"
   },
   "source": [
    "### Space\n",
    "\n",
    "Define spaces as in gym : https://github.com/openai/gym\n",
    "So it's easier to define parameters ranges etc in the system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MQQCgnsVNh_D"
   },
   "outputs": [],
   "source": [
    "class Space(object):\n",
    "    \"\"\"\n",
    "    Defines the init_space, genome_space and intervention_space of a system\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, shape=None, dtype=None):\n",
    "        self.shape = None if shape is None else tuple(shape)\n",
    "        self.dtype = dtype\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Randomly sample an element of this space.\n",
    "        Can be uniform or non-uniform sampling based on boundedness of space.\"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def mutate(self, x):\n",
    "        \"\"\"\n",
    "        Randomly mutate an element of this space.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def contains(self, x):\n",
    "        \"\"\"\n",
    "        Return boolean specifying if x is a valid\n",
    "        member of this space\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def clamp(self, x):\n",
    "        \"\"\"\n",
    "        Return a valid clamped value of x inside space's bounds\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def __contains__(self, x):\n",
    "        return self.contains(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "LHArCijHNk5H"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DiscreteSpace(Space):\n",
    "    r\"\"\"A discrete space in :math:`\\{ 0, 1, \\\\dots, n-1 \\}`.\n",
    "    /!\\ mutation is gaussian by default: please create custom space inheriting from discrete space for custom mutation functions\n",
    "\n",
    "    Example::\n",
    "\n",
    "        >>> DiscreteSpace(2)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n, mutation_mean=0.0, mutation_std=1.0, indpb=1.0):\n",
    "        assert n >= 0\n",
    "        self.n = n\n",
    "\n",
    "        # mutation_mean: mean for the gaussian addition mutation\n",
    "        # mutation_std: std for the gaussian addition mutation\n",
    "        # indpb – independent probability for each attribute to be mutated.\n",
    "        self.mutation_mean = torch.as_tensor(mutation_mean, dtype=torch.float64)\n",
    "        self.mutation_std = torch.as_tensor(mutation_std, dtype=torch.float64)\n",
    "        self.indpb = torch.as_tensor(indpb, dtype=torch.float64)\n",
    "        super(DiscreteSpace, self).__init__((), torch.int64)\n",
    "\n",
    "    def sample(self):\n",
    "        return torch.randint(self.n, ())\n",
    "\n",
    "    def mutate(self, x):\n",
    "        mutate_mask = torch.rand(self.shape) < self.indpb\n",
    "        noise = torch.normal(self.mutation_mean, self.mutation_std, ())\n",
    "        x = x.type(torch.float64) + mutate_mask * noise\n",
    "        x = torch.floor(x).type(self.dtype)\n",
    "        if not self.contains(x):\n",
    "            return self.clamp(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def contains(self, x):\n",
    "        if isinstance(x, int):\n",
    "            as_int = x\n",
    "        elif not x.dtype.is_floating_point and (x.shape == ()):  # integer or size 0\n",
    "            as_int = int(x)\n",
    "        else:\n",
    "            return False\n",
    "        return 0 <= as_int < self.n\n",
    "\n",
    "    def clamp(self, x):\n",
    "        x = torch.max(x, torch.as_tensor(0, dtype=self.dtype, device=x.device))\n",
    "        x = torch.min(x, torch.as_tensor(self.n - 1, dtype=self.dtype, device=x.device))\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"DiscreteSpace(%d)\" % self.n\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DiscreteSpace) and self.n == other.n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "SJtkOg_qNp7h"
   },
   "outputs": [],
   "source": [
    "\n",
    "class BoxSpace(Space):\n",
    "    \"\"\"\n",
    "    A (possibly unbounded) box in R^n. Specifically, a Box represents the\n",
    "    Cartesian product of n closed intervals. Each interval has the form of one\n",
    "    of [a, b], (-oo, b], [a, oo), or (-oo, oo).\n",
    "\n",
    "    There are two common use cases:\n",
    "\n",
    "    * Identical bound for each dimension::\n",
    "        >>> BoxSpace(low=-1.0, high=2.0, shape=(3, 4), dtype=torch.float32)\n",
    "        Box(3, 4)\n",
    "\n",
    "    * Independent bound for each dimension::\n",
    "        >>> BoxSpace(low=torch.tensor([-1.0, -2.0]), high=torch.tensor([2.0, 4.0]), dtype=torch.float32)\n",
    "        Box(2,)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, low, high, shape=None, dtype=torch.float32, mutation_mean=0.0, mutation_std=1.0, indpb=1.0):\n",
    "        assert dtype is not None, 'dtype must be explicitly provided. '\n",
    "        self.dtype = dtype\n",
    "\n",
    "        # determine shape if it isn't provided directly\n",
    "        if shape is not None:\n",
    "            shape = tuple(shape)\n",
    "            assert isinstance(low, numbers.Number) or low.shape == shape, \"low.shape doesn't match provided shape\"\n",
    "            assert isinstance(high, numbers.Number) or high.shape == shape, \"high.shape doesn't match provided shape\"\n",
    "        elif not isinstance(low, numbers.Number):\n",
    "            shape = low.shape\n",
    "            assert isinstance(high, numbers.Number) or high.shape == shape, \"high.shape doesn't match low.shape\"\n",
    "        elif not isinstance(high, numbers.Number):\n",
    "            shape = high.shape\n",
    "            assert isinstance(low, numbers.Number) or low.shape == shape, \"low.shape doesn't match high.shape\"\n",
    "        else:\n",
    "            raise ValueError(\"shape must be provided or inferred from the shapes of low or high\")\n",
    "\n",
    "        if isinstance(low, numbers.Number):\n",
    "            low = torch.full(shape, low, dtype=dtype)\n",
    "\n",
    "        if isinstance(high, numbers.Number):\n",
    "            high = torch.full(shape, high, dtype=dtype)\n",
    "\n",
    "        self.shape = shape\n",
    "        self.low = low.type(self.dtype)\n",
    "        self.high = high.type(self.dtype)\n",
    "\n",
    "        # Boolean arrays which indicate the interval type for each coordinate\n",
    "        self.bounded_below = ~torch.isneginf(self.low)\n",
    "        self.bounded_above = ~torch.isposinf(self.high)\n",
    "\n",
    "        # mutation_mean: mean for the gaussian addition mutation\n",
    "        # mutation_std: std for the gaussian addition mutation\n",
    "        # indpb – independent probability for each attribute to be mutated.\n",
    "        if isinstance(mutation_mean, numbers.Number):\n",
    "            mutation_mean = torch.full(self.shape, mutation_mean, dtype=torch.float64)\n",
    "        self.mutation_mean = torch.as_tensor(mutation_mean, dtype=torch.float64)\n",
    "        if isinstance(mutation_std, numbers.Number):\n",
    "            mutation_std = torch.full(self.shape, mutation_std, dtype=torch.float64)\n",
    "        self.mutation_std = torch.as_tensor(mutation_std, dtype=torch.float64)\n",
    "        if isinstance(indpb, numbers.Number):\n",
    "            indpb = torch.full(self.shape, indpb, dtype=torch.float64)\n",
    "        self.indpb = torch.as_tensor(indpb, dtype=torch.float64)\n",
    "\n",
    "        super(BoxSpace, self).__init__(self.shape, self.dtype)\n",
    "\n",
    "    def is_bounded(self, manner=\"both\"):\n",
    "        below = torch.all(self.bounded_below)\n",
    "        above = torch.all(self.bounded_above)\n",
    "        if manner == \"both\":\n",
    "            return below and above\n",
    "        elif manner == \"below\":\n",
    "            return below\n",
    "        elif manner == \"above\":\n",
    "            return above\n",
    "        else:\n",
    "            raise ValueError(\"manner is not in {'below', 'above', 'both'}\")\n",
    "\n",
    "    def sample(self):\n",
    "        \"\"\"\n",
    "        Generates a single random sample inside of the Box.\n",
    "\n",
    "        In creating a sample of the box, each coordinate is sampled according to\n",
    "        the form of the interval:\n",
    "\n",
    "        * [a, b] : uniform distribution\n",
    "        * [a, oo) : shifted exponential distribution\n",
    "        * (-oo, b] : shifted negative exponential distribution\n",
    "        * (-oo, oo) : normal distribution\n",
    "        \"\"\"\n",
    "        high = self.high.type(torch.float64) if self.dtype.is_floating_point else self.high.type(torch.int64) + 1\n",
    "        sample = torch.empty(self.shape, dtype=torch.float64)\n",
    "\n",
    "        # Masking arrays which classify the coordinates according to interval\n",
    "        # type\n",
    "        unbounded = ~self.bounded_below & ~self.bounded_above\n",
    "        upp_bounded = ~self.bounded_below & self.bounded_above\n",
    "        low_bounded = self.bounded_below & ~self.bounded_above\n",
    "        bounded = self.bounded_below & self.bounded_above\n",
    "\n",
    "        # Vectorized sampling by interval type\n",
    "        sample[unbounded] = torch.randn(unbounded[unbounded].shape, dtype=torch.float64)\n",
    "\n",
    "        sample[low_bounded] = (-torch.rand(low_bounded[low_bounded].shape, dtype=torch.float64)).exponential_() + \\\n",
    "                              self.low[low_bounded]\n",
    "\n",
    "        sample[upp_bounded] = self.high[upp_bounded] - (\n",
    "            -torch.rand(upp_bounded[upp_bounded].shape, dtype=torch.float64)).exponential_()\n",
    "\n",
    "        sample[bounded] = (self.low[bounded] - high[bounded]) * torch.rand(bounded[bounded].shape,\n",
    "                                                                           dtype=torch.float64) + high[bounded]\n",
    "\n",
    "        if not self.dtype.is_floating_point:  # integer\n",
    "            sample = torch.floor(sample)\n",
    "\n",
    "        return sample.type(self.dtype)\n",
    "\n",
    "    def mutate(self, x, mask=None):\n",
    "        if(mask==None):\n",
    "          mask=torch.ones(x.shape).to(x.device)\n",
    "\n",
    "        mutate_mask = mask*((torch.rand(self.shape) < self.indpb).type(torch.float64)).to(x.device)\n",
    "        noise = torch.normal(self.mutation_mean, self.mutation_std).to(x.device)\n",
    "        x = x.type(torch.float64) + mutate_mask * noise\n",
    "        if not self.dtype.is_floating_point:  # integer\n",
    "            x = torch.floor(x)\n",
    "        x = x.type(self.dtype)\n",
    "        if not self.contains(x):\n",
    "            return self.clamp(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def contains(self, x):\n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x)  # Promote list to array for contains check\n",
    "        return x.shape == self.shape and torch.all(x >= torch.as_tensor(self.low, dtype=self.dtype, device=x.device)) and torch.all(x <= torch.as_tensor(self.high, dtype=self.dtype, device=x.device))\n",
    "\n",
    "    def clamp(self, x):\n",
    "        if self.is_bounded(manner=\"below\"):\n",
    "            x = torch.max(x, torch.as_tensor(self.low, dtype=self.dtype, device=x.device))\n",
    "        if self.is_bounded(manner=\"above\"):\n",
    "            x = torch.min(x, torch.as_tensor(self.high, dtype=self.dtype, device=x.device))\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"BoxSpace({}, {}, {}, {})\".format(self.low.min(), self.high.max(), self.shape, self.dtype)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, BoxSpace) and (self.shape == other.shape) and torch.allclose(self.low,\n",
    "                                                                                              other.low) and torch.allclose(\n",
    "            self.high, other.high)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "ys-8enJ8PFrp"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DictSpace(Space):\n",
    "    \"\"\"\n",
    "    A Dict dictionary of simpler spaces.\n",
    "\n",
    "    Example usage:\n",
    "    self.genome_space = spaces.DictSpace({\"position\": spaces.Discrete(2), \"velocity\": spaces.Discrete(3)})\n",
    "\n",
    "    Example usage [nested]:\n",
    "    self.nested_genome_space = spaces.DictSpace({\n",
    "        'sensors':  spaces.DictSpace({\n",
    "            'position': spaces.Box(low=-100, high=100, shape=(3,)),\n",
    "            'velocity': spaces.Box(low=-1, high=1, shape=(3,)),\n",
    "            'front_cam': spaces.Tuple((\n",
    "                spaces.Box(low=0, high=1, shape=(10, 10, 3)),\n",
    "                spaces.Box(low=0, high=1, shape=(10, 10, 3))\n",
    "            )),\n",
    "            'rear_cam': spaces.Box(low=0, high=1, shape=(10, 10, 3)),\n",
    "        }),\n",
    "        'ext_controller': spaces.MultiDiscrete((5, 2, 2)),\n",
    "        'inner_state':spaces.DictSpace({\n",
    "            'charge': spaces.Discrete(100),\n",
    "            'system_checks': spaces.MultiBinary(10),\n",
    "            'job_status': spaces.DictSpace({\n",
    "                'task': spaces.Discrete(5),\n",
    "                'progress': spaces.Box(low=0, high=100, shape=()),\n",
    "            })\n",
    "        })\n",
    "    })\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, spaces=None, **spaces_kwargs):\n",
    "        assert (spaces is None) or (\n",
    "            not spaces_kwargs), 'Use either DictSpace(spaces=dict(...)) or DictSpace(foo=x, bar=z)'\n",
    "        if spaces is None:\n",
    "            spaces = spaces_kwargs\n",
    "        if isinstance(spaces, list):\n",
    "            spaces = Dict(spaces)\n",
    "        self.spaces = spaces\n",
    "        for space in spaces.values():\n",
    "            assert isinstance(space, Space), 'Values of the attrdict should be instances of gym.Space'\n",
    "        Space.__init__(self, None, None)  # None for shape and dtype, since it'll require special handling\n",
    "\n",
    "    def sample(self):\n",
    "        return Dict([(k, space.sample()) for k, space in self.spaces.items()])\n",
    "\n",
    "    def mutate(self, x):\n",
    "        return Dict([(k, space.mutate(x[k])) for k, space in self.spaces.items()])\n",
    "\n",
    "    def contains(self, x):\n",
    "        if not isinstance(x, dict) or len(x) != len(self.spaces):\n",
    "            return False\n",
    "        for k, space in self.spaces.items():\n",
    "            if k not in x:\n",
    "                return False\n",
    "            if not space.contains(x[k]):\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def clamp(self, x):\n",
    "        return Dict([(k, space.clamp(x[k])) for k, space in self.spaces.items()])\n",
    "\n",
    "    def __getitem__(self, key):\n",
    "        return self.spaces[key]\n",
    "\n",
    "    def __iter__(self):\n",
    "        for key in self.spaces:\n",
    "            yield key\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"DictSpace(\" + \", \".join([str(k) + \":\" + str(s) for k, s in self.spaces.items()]) + \")\"\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, DictSpace) and self.spaces == other.spaces\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "iEPQZNZUP5sC"
   },
   "outputs": [],
   "source": [
    "\n",
    "class MultiDiscreteSpace(Space):\n",
    "    \"\"\"\n",
    "    - The multi-discrete space consists of a series of discrete spaces with different number of possible instances in eachs\n",
    "    - Can be initialized as\n",
    "\n",
    "        MultiDiscreteSpace([ 5, 2, 2 ])\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, nvec, mutation_mean=0.0, mutation_std=1.0, indpb=1.0):\n",
    "\n",
    "        \"\"\"\n",
    "        nvec: vector of counts of each categorical variable\n",
    "        \"\"\"\n",
    "        assert (torch.tensor(nvec) > 0).all(), 'nvec (counts) have to be positive'\n",
    "        self.nvec = torch.as_tensor(nvec, dtype=torch.int64)\n",
    "        self.mutation_std = mutation_std\n",
    "\n",
    "        # mutation_mean: mean for the gaussian addition mutation\n",
    "        # mutation_std: std for the gaussian addition mutation\n",
    "        # indpb – independent probability for each attribute to be mutated.\n",
    "        if isinstance(mutation_mean, numbers.Number):\n",
    "            mutation_mean = torch.full(self.nvec.shape, mutation_mean, dtype=torch.float64)\n",
    "        self.mutation_mean = torch.as_tensor(mutation_mean, dtype=torch.float64)\n",
    "        if isinstance(mutation_std, numbers.Number):\n",
    "            mutation_std = torch.full(self.nvec.shape, mutation_std, dtype=torch.float64)\n",
    "        self.mutation_std = torch.as_tensor(mutation_std, dtype=torch.float64)\n",
    "        if isinstance(indpb, numbers.Number):\n",
    "            indpb = torch.full(self.nvec.shape, indpb, dtype=torch.float64)\n",
    "        self.indpb = torch.as_tensor(indpb, dtype=torch.float64)\n",
    "\n",
    "        super(MultiDiscreteSpace, self).__init__(self.nvec.shape, torch.int64)\n",
    "\n",
    "    def sample(self):\n",
    "        return (torch.rand(self.nvec.shape) * self.nvec).type(self.dtype)\n",
    "\n",
    "    def mutate(self, x):\n",
    "        mutate_mask = (torch.rand(self.shape) < self.indpb).to(x.device)\n",
    "        noise = torch.normal(self.mutation_mean, self.mutation_std).to(x.device)\n",
    "        x = x.type(torch.float64) + mutate_mask * noise\n",
    "        x = torch.floor(x).type(self.dtype)\n",
    "        if not self.contains(x):\n",
    "            return self.clamp(x)\n",
    "        else:\n",
    "            return x\n",
    "\n",
    "    def contains(self, x):\n",
    "        if isinstance(x, list):\n",
    "            x = torch.tensor(x)  # Promote list to array for contains check\n",
    "        # if nvec is uint32 and space dtype is uint32, then 0 <= x < self.nvec guarantees that x\n",
    "        # is within correct bounds for space dtype (even though x does not have to be unsigned)\n",
    "        return x.shape == self.shape and (0 <= x).all() and (x < self.nvec).all()\n",
    "\n",
    "    def clamp(self, x):\n",
    "        x = torch.max(x, torch.as_tensor(0, dtype=self.dtype, device=x.device))\n",
    "        x = torch.min(x, torch.as_tensor(self.nvec - 1, dtype=self.dtype, device=x.device))\n",
    "        return x\n",
    "\n",
    "    def __repr__(self):\n",
    "        return \"MultiDiscreteSpace({})\".format(self.nvec)\n",
    "\n",
    "    def __eq__(self, other):\n",
    "        return isinstance(other, MultiDiscreteSpace) and torch.all(self.nvec == other.nvec)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "sVxUZgeTsgDr"
   },
   "outputs": [],
   "source": [
    "\n",
    "class BoxGoalSpace(BoxSpace):\n",
    "    def __init__(self, representation, autoexpand=True, low=0., high=0., shape=None, dtype=torch.float32):\n",
    "        self.representation = representation\n",
    "        self.autoexpand = autoexpand\n",
    "        if shape is not None:\n",
    "            if isinstance(shape, list) or isinstance(shape, tuple):\n",
    "                assert len(shape) == 1 and shape[0] == self.representation.n_latents\n",
    "            elif isinstance(shape, numbers.Number):\n",
    "                assert shape == self.representation.n_latents\n",
    "        BoxSpace.__init__(self, low=low, high=high, shape=(self.representation.n_latents,), dtype=dtype)\n",
    "\n",
    "    def map(self, observations, **kwargs):\n",
    "        embedding = self.representation.calc(observations, **kwargs)\n",
    "        if self.autoexpand:\n",
    "            embedding_c = embedding.detach()\n",
    "            is_nan_mask = torch.isnan(embedding_c)\n",
    "            if is_nan_mask.sum() > 0:\n",
    "                embedding_c[is_nan_mask] = self.low[is_nan_mask]\n",
    "                self.low = torch.min(self.low, embedding_c)\n",
    "                embedding_c[is_nan_mask] = self.high[is_nan_mask]\n",
    "                self.high = torch.max(self.high, embedding_c)\n",
    "            else:\n",
    "                self.low = torch.min(self.low, embedding_c)\n",
    "                self.high = torch.max(self.high, embedding_c)\n",
    "        return embedding\n",
    "\n",
    "    def calc_distance(self, embedding_a, embedding_b, **kwargs):\n",
    "        return self.representation.calc_distance(embedding_a, embedding_b, **kwargs)\n",
    "\n",
    "    def sample(self):\n",
    "        return BoxSpace.sample(self)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dQSmxLcg-nTx"
   },
   "source": [
    "## exploration database\n",
    "\n",
    "only to store the parameters in an easy way, part of a bigger modular class . Not particularly interesting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "ETo3qGZ8-pd8"
   },
   "outputs": [],
   "source": [
    "class RunDataEntry(Dict):\n",
    "    \"\"\"\n",
    "    Class that specify for RunData entry in the DB\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, db, id, policy_parameters, observations, **kwargs):\n",
    "        \"\"\"\n",
    "        :param kwargs: flexible structure of the entry which might contain additional columns (eg: source_policy_idx, target_goal, etc.)\n",
    "        \"\"\"\n",
    "        super().__init__(**kwargs)\n",
    "        self.db = db\n",
    "        self.id = id\n",
    "        self.policy_parameters = policy_parameters\n",
    "        self.observations = observations\n",
    "\n",
    "class ExplorationDB:\n",
    "    \"\"\"\n",
    "    Base of all Database classes.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "\n",
    "        default_config = Dict()\n",
    "        default_config.db_directory = \"database\"\n",
    "        default_config.save_observations = True\n",
    "        default_config.keep_saved_runs_in_memory = True\n",
    "        default_config.memory_size_run_data = 'infinity'  # number of runs that are kept in memory: 'infinity' - no imposed limit, int - number of runs saved in memory\n",
    "        default_config.load_observations = True  # if set to false observations are not loaded in the load() function\n",
    "\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, config={}, **kwargs):\n",
    "\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "\n",
    "        if self.config.memory_size_run_data != 'infinity':\n",
    "            assert isinstance(self.config.memory_size_run_data,\n",
    "                              int) and self.config.memory_size_run_data > 0, \"config.memory_size_run_data must be set to infinity or to an integer >= 1\"\n",
    "\n",
    "        self.reset_empty_db()\n",
    "\n",
    "    def reset_empty_db(self):\n",
    "        self.runs = OrderedDict()\n",
    "        self.run_ids = set()  # list with run_ids that exist in the db\n",
    "        self.run_data_ids_in_memory = []  # list of run_ids that are hold in memory\n",
    "\n",
    "    def add_run_data(self, id, policy_parameters, observations, **kwargs):\n",
    "\n",
    "        run_data_entry = RunDataEntry(db=self, id=id, policy_parameters=policy_parameters, observations=observations,\n",
    "                                      **kwargs)\n",
    "        if id not in self.run_ids:\n",
    "            self.add_run_data_to_memory(id, run_data_entry)\n",
    "            self.run_ids.add(id)\n",
    "\n",
    "        else:\n",
    "            warnings.warn(f'/!\\ id {id} already in the database: overwriting it with new run data !!!')\n",
    "            self.add_run_data_to_memory(id, run_data_entry, replace_existing=True)\n",
    "\n",
    "        self.save([id])  # TODO: modify if we do not want to automatically save after each run\n",
    "\n",
    "    def add_run_data_to_memory(self, id, run_data, replace_existing=False):\n",
    "        self.runs[id] = run_data\n",
    "        if not replace_existing:\n",
    "            self.run_data_ids_in_memory.insert(0, id)\n",
    "\n",
    "        # remove last item from memory when not enough size\n",
    "        if self.config.memory_size_run_data != 'infinity' and len(\n",
    "                self.run_data_ids_in_memory) > self.config.memory_size_run_data:\n",
    "            del (self.runs[self.run_data_ids_in_memory[-1]])\n",
    "            del (self.run_data_ids_in_memory[-1])\n",
    "\n",
    "    def save(self, run_ids=None):\n",
    "        # the run data entry is save in 2 files: 'run_*_data*' (general data dict such as run parameters -> for now json) and ''run_*_observations*' (observation data dict -> for now npz)\n",
    "        if run_ids is None:\n",
    "            run_ids = []\n",
    "\n",
    "        for run_id in run_ids:\n",
    "            self.save_run_data_to_db(run_id)\n",
    "            if self.config.save_observations:\n",
    "                self.save_observations_to_db(run_id)\n",
    "\n",
    "        if not self.config.keep_saved_runs_in_memory:\n",
    "            for run_id in run_ids:\n",
    "                del self.runs[run_id]\n",
    "            self.run_data_ids_in_memory = []\n",
    "\n",
    "    def save_run_data_to_db(self, run_id):\n",
    "        run_data = self.runs[run_id]\n",
    "\n",
    "        # add all data besides the observations\n",
    "        save_dict = dict()\n",
    "        for data_name, data_value in run_data.items():\n",
    "            if data_name not in ['observations', 'db']:\n",
    "                save_dict[data_name] = data_value\n",
    "        filename = 'run_{:07d}_data.pickle'.format(run_id)\n",
    "        filepath = os.path.join(self.config.db_directory, filename)\n",
    "\n",
    "        torch.save(save_dict, filepath)\n",
    "\n",
    "    def save_observations_to_db(self, run_id):\n",
    "        # TODO: create an abstract observation class with a save method for observations that are not numpy array\n",
    "        run_data = self.runs[run_id]\n",
    "\n",
    "        filename = 'run_{:07d}_observations.pickle'.format(run_id)\n",
    "        filepath = os.path.join(self.config.db_directory, filename)\n",
    "\n",
    "        torch.save(run_data.observations, filepath)\n",
    "\n",
    "    def load(self, run_ids=None, map_location=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Loads the data base.\n",
    "        :param run_ids:  IDs of runs for which the data should be loaded into the memory.\n",
    "                        If None is given, all ids are loaded (up to the allowed memory size).\n",
    "        :param map_location: device on which the database is loaded\n",
    "        \"\"\"\n",
    "\n",
    "        if run_ids is not None:\n",
    "            assert isinstance(run_ids, list), \"run_ids must be None or a list\"\n",
    "\n",
    "        # set run_ids from the db directory and empty memory\n",
    "        self.run_ids = self.load_run_ids_from_db()\n",
    "        self.runs = OrderedDict()\n",
    "        self.run_data_ids_in_memory = []\n",
    "\n",
    "        if run_ids is None:\n",
    "            run_ids = self.run_ids\n",
    "\n",
    "        if len(run_ids) > 0:\n",
    "\n",
    "            if self.config.memory_size_run_data != 'infinity' and len(run_ids) > self.config.memory_size_run_data:\n",
    "                # only load the maximum number of run_data into the memory\n",
    "                run_ids = list(run_ids)[-self.config.memory_size_run_data:]\n",
    "\n",
    "            self.load_run_data_from_db(run_ids, map_location=map_location)\n",
    "\n",
    "    def load_run_ids_from_db(self):\n",
    "        run_ids = set()\n",
    "\n",
    "        file_matches = glob(os.path.join(self.config.db_directory, 'run_*_data*'))\n",
    "        for match in file_matches:\n",
    "            id_as_str = re.findall('_(\\d+).', match)\n",
    "            if len(id_as_str) > 0:\n",
    "                run_ids.add(int(id_as_str[\n",
    "                                    -1]))  # use the last find, because ther could be more number in the filepath, such as in a directory name\n",
    "\n",
    "        return run_ids\n",
    "\n",
    "    def load_run_data_from_db(self, run_ids, map_location=\"cpu\"):\n",
    "        \"\"\"Loads the data for a list of runs and adds them to the memory.\"\"\"\n",
    "\n",
    "        if not os.path.exists(self.config.db_directory):\n",
    "            raise Exception('The directory {!r} does not exits! Cannot load data.'.format(self.config.db_directory))\n",
    "\n",
    "        print('Loading Data: ')\n",
    "        for run_id in tqdm(run_ids):\n",
    "            # load general data (run parameters and others)\n",
    "            filename = 'run_{:07d}_data.pickle'.format(run_id)\n",
    "            filepath = os.path.join(self.config.db_directory, filename)\n",
    "\n",
    "            if os.path.exists(filepath):\n",
    "                run_data_kwargs = torch.load(filepath, map_location=map_location)\n",
    "            else:\n",
    "                run_data_kwargs = {'id': None, 'policy_parameters': None}\n",
    "\n",
    "            if self.config.load_observations:\n",
    "                filename_obs = 'run_{:07d}_observations.pickle'.format(run_id)\n",
    "                filepath_obs = os.path.join(self.config.db_directory, filename_obs)\n",
    "\n",
    "                # load observations\n",
    "                if os.path.exists(filepath_obs):\n",
    "                    observations = torch.load(filepath_obs, map_location=map_location)\n",
    "                else:\n",
    "                    observations = None\n",
    "            else:\n",
    "                observations = None\n",
    "\n",
    "            # create run data and add it to memory\n",
    "            run_data = RunDataEntry(self, observations=observations, **run_data_kwargs)\n",
    "            self.add_run_data_to_memory(run_id, run_data)\n",
    "\n",
    "            if not self.config.keep_saved_runs_in_memory:\n",
    "                del self.runs[run_id]\n",
    "                del self.run_data_ids_in_memory[0]\n",
    "\n",
    "        return\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fVgTKx6qfDE9"
   },
   "source": [
    "## Demo code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EF1AQGF7es8P",
    "outputId": "f4fdf98f-120d-4a1a-955a-d95b233a931b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: Js2Py in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (0.74)\n",
      "Requirement already satisfied: tzlocal>=1.2 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from Js2Py) (5.2)\n",
      "Requirement already satisfied: six>=1.10 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from Js2Py) (1.16.0)\n",
      "Requirement already satisfied: pyjsparser>=2.5.1 in /Users/arsnm/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages (from Js2Py) (2.7.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install Js2Py\n",
    "from IPython.display import HTML\n",
    "from js2py import eval_js\n",
    "from base64 import b64decode\n",
    "\n",
    "canvas_html = \"\"\"\n",
    "\n",
    "<canvas width=%s height=%s style=\"border: 1px solid black;\"></canvas><br><br>\n",
    "<div class=\"radio-toolbar\" id=\"optionDiv\">\n",
    "    <input type=\"radio\" id=\"radioDraw\" name='option'   value=\"draw\" checked>\n",
    "    <label for=\"radioDraw\">Pencil</label>\n",
    "\n",
    "    <input type=\"radio\" id=\"radioErase\"  name='option'  value=\"erase\">\n",
    "    <label for=\"radioErase\">Eraser</label>\n",
    "\n",
    "    <input type=\"radio\" id=\"radioCircle\"  name='option'  value=\"circle\">\n",
    "    <label for=\"radioCircle\">Dot</label>\n",
    "\n",
    "    <input type=\"radio\" id=\"radioCreature\" name='option'  value=\"creature\">\n",
    "    <label for=\"radioCreature\">Place Creature</label>\n",
    "</div><br><br>\n",
    "\n",
    "\n",
    "\n",
    "<button id='clearButton'>Clear All</button>\n",
    "<button id='finishButton'>Generate Video</button>\n",
    "<button id='resetButton'>reset param</button>\n",
    "<button id='stopButton' style=\"background_color: red;\">Stop the notebook</button><br><br>\n",
    "\n",
    "\n",
    "\n",
    "<div class=\"slidecontainer\">\n",
    "  <label for=\"rangeCircle\">Radius of dot:</label>\n",
    "  <input type=\"range\" min=\"1\" max=\"40\" value=\"10\" class=\"slider\" id=\"rangeCircle\">\n",
    "  <p>Value: <span id=\"valueCircle\"></span></p>\n",
    "</div>\n",
    "\n",
    "<div class=\"slidecontainerVisible\">\n",
    "  <label for=\"rangeSteps\">Number of timesteps:</label>\n",
    "  <input type=\"range\" min=\"100\" max=\"1000\" step=\"10\" value=\"%s\" class=\"slider\" id=\"rangeSteps\">\n",
    "  <p>Value: <span id=\"valueSteps\"></span></p>\n",
    "</div>\n",
    "\n",
    "\n",
    "<div class=\"radio-toolbar\" id=\"optionDivKernels\">\n",
    "    <input type=\"radio\" id=\"radioKernel0\" name='optionK'   value=\"0\">\n",
    "    <label for=\"radioKernel0\">0</label>\n",
    "    <input type=\"radio\" id=\"radioKernel1\" name='optionK'  value=\"1\" >\n",
    "    <label for=\"radioKernel1\">1</label>\n",
    "    <input type=\"radio\" id=\"radioKernel2\" name='optionK'  value=\"2\" >\n",
    "    <label for=\"radioKernel2\">2</label>\n",
    "    <input type=\"radio\" id=\"radioKernel3\"  name='optionK' value=\"3\" >\n",
    "    <label for=\"radioKernel3\">3</label>\n",
    "    <input type=\"radio\" id=\"radioKernel4\" name='optionK'  value=\"4\" >\n",
    "    <label for=\"radioKernel4\">4</label>\n",
    "    <input type=\"radio\" id=\"radioKernel5\" name='optionK'  value=\"5\" >\n",
    "    <label for=\"radioKernel5\">5</label>\n",
    "    <input type=\"radio\" id=\"radioKernel6\"  name='optionK' value=\"6\" >\n",
    "    <label for=\"radioKernel6\">6</label>\n",
    "    <input type=\"radio\" id=\"radioKernel7\"  name='optionK' value=\"7\" >\n",
    "    <label for=\"radioKernel7\">7</label>\n",
    "    <input type=\"radio\" id=\"radioKernel8\"  name='optionK' value=\"8\" >\n",
    "    <label for=\"radioKernel8\">8</label>\n",
    "    <input type=\"radio\" id=\"radioKernel9\"  name='optionK' value=\"9\" >\n",
    "    <label for=\"radioKernel9\">9</label>\n",
    "</div><br><br>\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "kernels_HTML=\"\"\"\n",
    "<div class=\"slidecontainerHidden\" id='slider{i}'>\n",
    "  <label for=\"rangeh\">h:</label>\n",
    "  <input type=\"range\" min=\"0\" max=\"1\" step=\"0.001\" value=\"{h}\" class=\"slider\" id=\"sliderh{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valueh{i}\"></span></p>\n",
    "  <label for=\"rangem\">m:</label>\n",
    "  <input type=\"range\" min=\"0\" max=\"0.5\" step=\"0.001\" value=\"{m}\" class=\"slider\" id=\"sliderm{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valuem{i}\"></span></p>\n",
    "  <label for=\"ranges\">s:</label>\n",
    "  <input type=\"range\" min=\"0.001\" max=\"0.3\" step=\"0.0005\" value=\"{s}\" class=\"slider\" id=\"sliders{i}\" name=\"sliderk\">\n",
    "  <p>Value: <span id=\"values{i}\"></span></p>\n",
    "  <label for=\"ranger\">r:</label>\n",
    "  <input type=\"range\" min=\"0.01\" max=\"1\" step=\"0.001\" value=\"{r}\" class=\"slider\" id=\"sliderr{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valuer{i}\"></span></p>\n",
    "  <label for=\"rangerk1\">rk1:</label>\n",
    "  <input type=\"range\" min=\"0\" max=\"1\" step=\"0.001\" value=\"{rk1}\" class=\"slider\" id=\"sliderrk1{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valuerk1{i}\"></span></p>\n",
    "  <label for=\"rangerk2\">rk2:</label>\n",
    "  <input type=\"range\" min=\"0\" max=\"1\" step=\"0.001\" value=\"{rk2}\" class=\"slider\" id=\"sliderrk2{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valuerk2{i}\"></span></p>\n",
    "  <label for=\"rangerk3\">rk3:</label>\n",
    "  <input type=\"range\" min=\"0\" max=\"1\" step=\"0.001\" value=\"{rk3}\" class=\"slider\" id=\"sliderrk3{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valuerk3{i}\"></span></p>\n",
    "  <label for=\"rangew1\">w1:</label>\n",
    "  <input type=\"range\" min=\"0.01\" max=\"0.5\" step=\"0.001\" value=\"{w1}\" class=\"slider\" id=\"sliderw1{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valuew1{i}\"></span></p>\n",
    "  <label for=\"rangew2\">w2:</label>\n",
    "  <input type=\"range\" min=\"0.01\" max=\"0.5\" step=\"0.001\" value=\"{w2}\" class=\"slider\" id=\"sliderw2{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valuew2{i}\"></span></p>\n",
    "  <label for=\"rangew3\">w3:</label>\n",
    "  <input type=\"range\" min=\"0.01\" max=\"0.5\" step=\"0.001\" value=\"{w3}\" class=\"slider\" id=\"sliderw3{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valuew3{i}\"></span></p>\n",
    "  <label for=\"rangeb1\">b1:</label>\n",
    "  <input type=\"range\" min=\"0\" max=\"1\" step=\"0.005\" value=\"{b1}\" class=\"slider\" id=\"sliderb1{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valueb1{i}\"></span></p>\n",
    "  <label for=\"rangeb2\">b2:</label>\n",
    "  <input type=\"range\" min=\"0\" max=\"1\" step=\"0.005\" value=\"{b2}\" class=\"slider\" id=\"sliderb2{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valueb2{i}\"></span></p>\n",
    "  <label for=\"rangeb3\">b3:</label>\n",
    "  <input type=\"range\" min=\"0\" max=\"1\" step=\"0.005\" value=\"{b3}\" class=\"slider\" id=\"sliderb3{i}\" name=\"sliderK\">\n",
    "  <p>Value: <span id=\"valueb3{i}\"></span></p>\n",
    "</div>\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "\n",
    "end_HTML=\"\"\"\n",
    "<script>\n",
    "var canvas = document.querySelector('canvas')\n",
    "var ctx = canvas.getContext('2d')\n",
    "ctx.lineWidth = %s\n",
    "var button = document.getElementById('finishButton')\n",
    "var buttonClear= document.getElementById('clearButton')\n",
    "var buttonStop= document.getElementById('stopButton')\n",
    "var buttonReset= document.getElementById('resetButton')\n",
    "var mouse = {x: 0, y: 0}\n",
    "\n",
    "var data_url=\"%s\"\n",
    "var sliderCircle = document.getElementById(\"rangeCircle\");\n",
    "var outputCircle = document.getElementById(\"valueCircle\");\n",
    "\n",
    "var sliderSteps = document.getElementById(\"rangeSteps\");\n",
    "var outputSteps = document.getElementById(\"valueSteps\");\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "canvas.addEventListener('mousemove', function(e) {\n",
    "  mouse.x = e.pageX - this.offsetLeft\n",
    "  mouse.y = e.pageY - this.offsetTop\n",
    "\n",
    "})\n",
    "\n",
    "canvas.addEventListener('mousedown', function(e) {\n",
    "    var options = document.getElementsByName('option');\n",
    "    var selected;\n",
    "    for(var i = 0; i < options.length; i++){\n",
    "        if(options[i].checked){\n",
    "            selected = options[i].value;\n",
    "        }\n",
    "    }\n",
    "    if(selected=='draw'){\n",
    "    ctx.beginPath()\n",
    "    ctx.moveTo(mouse.x, mouse.y)\n",
    "    canvas.addEventListener('mousemove', onPaint)\n",
    "    }\n",
    "    if(selected=='erase'){\n",
    "    ctx.beginPath()\n",
    "    canvas.addEventListener('mousemove',onErase)\n",
    "    }\n",
    "    if(selected=='circle'){\n",
    "    mouse.x = e.pageX - this.offsetLeft\n",
    "    mouse.y = e.pageY - this.offsetTop\n",
    "    ctx.beginPath()\n",
    "    ctx.arc(mouse.x, mouse.y, sliderCircle.value, 0, 2 * Math.PI)\n",
    "    ctx.fill()\n",
    "    }\n",
    "    if(selected=='creature'){\n",
    "\n",
    "      mouse.x = e.pageX - this.offsetLeft\n",
    "      mouse.y = e.pageY - this.offsetTop\n",
    "      ctx.fillStyle = \"red\";\n",
    "      ctx.beginPath();\n",
    "      ctx.rect(mouse.x-20, mouse.y-20, 40, 40);\n",
    "      ctx.fill();\n",
    "      ctx.fillStyle = \"black\";\n",
    "\n",
    "    }\n",
    "\n",
    "})\n",
    "canvas.onmouseup = ()=>{\n",
    "  var options = document.getElementsByName('option');\n",
    "    var selected;\n",
    "    for(var i = 0; i < options.length; i++){\n",
    "        if(options[i].checked){\n",
    "            selected = options[i].value;\n",
    "        }\n",
    "    }\n",
    "  if(selected=='draw'){\n",
    "    canvas.removeEventListener('mousemove', onPaint)\n",
    "  }\n",
    "  if(selected=='erase'){\n",
    "    canvas.removeEventListener('mousemove', onErase)\n",
    "  }\n",
    "\n",
    "}\n",
    "var onPaint = ()=>{\n",
    "  ctx.lineTo(mouse.x, mouse.y)\n",
    "  ctx.stroke()\n",
    "}\n",
    "\n",
    "var onErase = ()=>{\n",
    "  ctx.clearRect(mouse.x-10, mouse.y-10,20,20)\n",
    "}\n",
    "\n",
    "\n",
    "buttonClear.onclick= ()=>{\n",
    "  ctx.clearRect(0, 0, canvas.width, canvas.height);\n",
    "}\n",
    "\n",
    "\n",
    "outputCircle.innerHTML = sliderCircle.value; // Display the default slider value\n",
    "sliderCircle.oninput = function() {\n",
    "  outputCircle.innerHTML = this.value;\n",
    "}\n",
    "\n",
    "outputSteps.innerHTML = sliderSteps.value; // Display the default slider value\n",
    "// Update the current slider value (each time you drag the slider handle)\n",
    "sliderSteps.oninput = function() {\n",
    "  outputSteps.innerHTML = this.value;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "let btns = document.getElementsByName(\"optionK\")\n",
    "\n",
    "for (i of btns) {\n",
    "  i.addEventListener('click', function() {\n",
    "\n",
    "    for(var j=0;j<10;j++){\n",
    "      if(j==this.value){\n",
    "        document.getElementById(\"slider\"+j).className=\"slidecontainerVisible\";\n",
    "      }\n",
    "      else{\n",
    "        document.getElementById(\"slider\"+j).className=\"slidecontainerHidden\";\n",
    "      }\n",
    "    }\n",
    "  });\n",
    "}\n",
    "\n",
    "let sliders = document.getElementsByName(\"sliderK\")\n",
    "console.log(sliders)\n",
    "for (i of sliders){\n",
    "    document.getElementById('value'+i.id.slice(6)).innerHTML = i.value; // Display the default slider value\n",
    "    i.oninput = function() {\n",
    "      document.getElementById('value'+this.id.slice(6)).innerHTML = this.value;\n",
    "    }\n",
    "}\n",
    "\n",
    "console.log(data_url)\n",
    "if(data_url.charAt(0)=='d'){\n",
    "  var imageObj = new Image();\n",
    "  imageObj.onload = function() {\n",
    "    ctx.drawImage(this, 0, 0);\n",
    "\n",
    "  };\n",
    "  imageObj.src = data_url;\n",
    "\n",
    "}\n",
    "\n",
    "var data = new Promise(resolve=>{\n",
    "  button.onclick = ()=>{\n",
    "    var msg=\"1\"+(\"000\"+sliderSteps.value).slice(-4)+\",\"\n",
    "    for (var i = 0; i < 10; i++) {\n",
    "      msg+=  document.getElementById('sliderh'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderm'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliders'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderr'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderrk1'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderrk2'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderrk3'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderw1'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderw2'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderw3'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderb1'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderb2'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderb3'+i).value+\",\"\n",
    "    }\n",
    "    resolve(msg+canvas.toDataURL('image/png'))\n",
    "  }\n",
    "  buttonStop.onclick = ()=>{\n",
    "    /*\n",
    "    ctx.beginPath();\n",
    "    ctx.fillStyle = \"green\";\n",
    "    ctx.rect(0, 0, 1, 1)\n",
    "    ctx.fill();\n",
    "    ctx.fillStyle = \"black\";\n",
    "    */\n",
    "\n",
    "    resolve(\"0\")\n",
    "  }\n",
    "  buttonReset.onclick = ()=>{\n",
    "\n",
    "    var msg=\"2\"+(\"000\"+sliderSteps.value).slice(-4)+\",\"\n",
    "    for (var i = 0; i < 10; i++) {\n",
    "      msg+=  document.getElementById('sliderh'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderm'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliders'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderr'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderrk1'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderrk2'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderrk3'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderw1'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderw2'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderw3'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderb1'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderb2'+i).value+\",\"\n",
    "      msg+=  document.getElementById('sliderb3'+i).value+\",\"\n",
    "    }\n",
    "    resolve(msg+canvas.toDataURL('image/png'))\n",
    "  }\n",
    "\n",
    "})\n",
    "</script>\n",
    "\n",
    "<style>\n",
    "button {\n",
    "display: inline-block;\n",
    "background-color: #7b38d8;\n",
    "border-radius: 10px;\n",
    "border: 4px double #cccccc;\n",
    "color: #eeeeee;\n",
    "text-align: center;\n",
    "font-size: 15px;\n",
    "padding: 10px;\n",
    "width: 80px;\n",
    "-webkit-transition: all 0.5s;\n",
    "-moz-transition: all 0.5s;\n",
    "-o-transition: all 0.5s;\n",
    "transition: all 0.5s;\n",
    "cursor: pointer;\n",
    "margin: 5px;\n",
    "}\n",
    "button:hover {\n",
    "background-color: lightgreen;\n",
    "}\n",
    "\n",
    ".radio-toolbar input[type=\"radio\"] {\n",
    "  opacity: 0;\n",
    "  position: fixed;\n",
    "  width: 0;\n",
    "}\n",
    "\n",
    ".radio-toolbar label {\n",
    "    display: inline-block;\n",
    "    background-color: #7b38d8;\n",
    "    border-radius: 10px;\n",
    "    border: 4px double #cccccc;\n",
    "    color: #eeeeee;\n",
    "    text-align: center;\n",
    "    font-size: 15px;\n",
    "    padding: 10px;\n",
    "    width: 80px;\n",
    "    -webkit-transition: all 0.5s;\n",
    "    -moz-transition: all 0.5s;\n",
    "    -o-transition: all 0.5s;\n",
    "    transition: all 0.5s;\n",
    "    cursor: pointer;\n",
    "    margin: 5px;\n",
    "}\n",
    "\n",
    ".radio-toolbar input[type=\"radio\"]:checked + label {\n",
    "    background-color:green;\n",
    "    border-color: #4c4;\n",
    "}\n",
    "\n",
    ".radio-toolbar input[type=\"radio\"]:focus + label {\n",
    "    border: 2px dashed #444;\n",
    "}\n",
    "\n",
    ".radio-toolbar label:hover {\n",
    "  background-color: lightgreen;\n",
    "}\n",
    "\n",
    ".slidecontainerVisible {\n",
    "  width: 320px;\n",
    "  display:block;\n",
    "}\n",
    ".slidecontainerHidden {\n",
    "  display:none;\n",
    "}\n",
    "\n",
    ".slider {\n",
    "  -webkit-appearance: none;\n",
    "  width: 320px;\n",
    "  height: 15px;\n",
    "  border-radius: 5px;\n",
    "  background: #d3d3d3;\n",
    "  outline: none;\n",
    "  opacity: 0.7;\n",
    "  -webkit-transition: .2s;\n",
    "  transition: opacity .2s;\n",
    "}\n",
    "\n",
    ".slider:hover {\n",
    "  opacity: 1;\n",
    "}\n",
    "\n",
    ".slider::-webkit-slider-thumb {\n",
    "  -webkit-appearance: none;\n",
    "  appearance: none;\n",
    "  width: 25px;\n",
    "  height: 25px;\n",
    "  border-radius: 12px;\n",
    "  background: #04AA6D;\n",
    "  cursor: pointer;\n",
    "}\n",
    "\n",
    ".slider::-moz-range-thumb {\n",
    "  width: 25px;\n",
    "  height: 25px;\n",
    "  border-radius: 12px;\n",
    "  background: #04AA6D;\n",
    "  cursor: pointer;\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "</style>\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "8OUi7r-LfJFr"
   },
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "import matplotlib.cm as cm\n",
    "import cv2\n",
    "def main(SX,SY,mode,borders,list_kernels=range(10),creaFile=\"crea1.pickle\",modeb='none',zoom=1):\n",
    "  lenia_config = Lenia_C.default_config()\n",
    "  lenia_config.SX = SX\n",
    "  lenia_config.SY = SY\n",
    "  lenia_config.final_step = 200\n",
    "  lenia_config.version = 'pytorch_fft'\n",
    "  lenia_config.nb_kernels=len(list_kernels)\n",
    "  initialization_space_config=Dict()\n",
    "  initialization_space = LeniaInitializationSpace(config=initialization_space_config)\n",
    "  system = Lenia_C(initialization_space=initialization_space, config=lenia_config, device='cuda')\n",
    "  a=torch.load(creaFile)\n",
    "\n",
    "\n",
    "  # b=torch.load(\"run_0000179_data.pickle\")\n",
    "  policy_parameters = Dict.fromkeys(['initialization', 'update_rule'])\n",
    "  policy_parameters['initialization']=a['policy_parameters']['initialization']\n",
    "  policy_parameters['update_rule']=a['policy_parameters']['update_rule']\n",
    "\n",
    "  # random_kernels=torch.randperm(10)[:9]\n",
    "\n",
    "  policy_parameters['update_rule']['R']=(policy_parameters['update_rule']['R']+15)*zoom-15\n",
    "  init_s=policy_parameters['initialization'].init.cpu().numpy()*1.0\n",
    "\n",
    "\n",
    "  width = int(init_s.shape[1]*zoom)\n",
    "  height = int(init_s.shape[0]* zoom)\n",
    "  dim = (width, height)\n",
    "  # resize image\n",
    "  resized = cv2.resize(init_s,dim)\n",
    "  init_f=torch.tensor(resized).to('cuda')\n",
    "\n",
    "  for k in policy_parameters['update_rule'].keys():\n",
    "\n",
    "\n",
    "    if(k!='R' and k!='T'):\n",
    "\n",
    "      policy_parameters['update_rule'][k]=policy_parameters['update_rule'][k][list_kernels]\n",
    "    policy_parameters['update_rule'][k]=policy_parameters['update_rule'][k].to('cuda')\n",
    "\n",
    "  system.reset(initialization_parameters=policy_parameters['initialization'],update_rule_parameters=policy_parameters['update_rule'])\n",
    "  creature_x=-40\n",
    "  creature_y=-40\n",
    "  data_split=[\"a\",\"a\"]\n",
    "\n",
    "\n",
    "  while True:\n",
    "    if(mode=='draw'):\n",
    "      print('you can draw on the canvas or click on circle to go to circle mode')\n",
    "      print('click on video once you re done')\n",
    "      data=['2']\n",
    "      while(data[0]=='2'):\n",
    "\n",
    "        cv_HTML=canvas_html % (SY, SX,system.config.final_step)\n",
    "\n",
    "        for i in range(10):\n",
    "          cv_HTML=cv_HTML+kernels_HTML.format(i=i,\n",
    "                                      h=policy_parameters['update_rule']['h'][i],\n",
    "                                      m=policy_parameters['update_rule']['m'][i],\n",
    "                                      s=policy_parameters['update_rule']['s'][i],\n",
    "                                      r=policy_parameters['update_rule']['r'][i],\n",
    "                                      rk1=policy_parameters['update_rule']['rk'][i][0],\n",
    "                                      rk2=policy_parameters['update_rule']['rk'][i][1],\n",
    "                                      rk3=policy_parameters['update_rule']['rk'][i][2],\n",
    "                                      w1=policy_parameters['update_rule']['w'][i][0],\n",
    "                                      w2=policy_parameters['update_rule']['w'][i][1],\n",
    "                                      w3=policy_parameters['update_rule']['w'][i][2],\n",
    "                                      b1=policy_parameters['update_rule']['b'][i][0],\n",
    "                                      b2=policy_parameters['update_rule']['b'][i][1],\n",
    "                                      b3=policy_parameters['update_rule']['b'][i][2])\n",
    "\n",
    "        cv_HTML=cv_HTML+end_HTML %( 8,data_split[-2]+\",\"+data_split[-1])\n",
    "        # print(cv_HTML)\n",
    "\n",
    "        html_object=HTML(cv_HTML)\n",
    "        # print(canvas_html % (SY, SX, 8,creature_x,creature_y,data_url))\n",
    "        display(html_object)\n",
    "\n",
    "\n",
    "        data = eval_js('data')\n",
    "        if(data[0]=='2'):\n",
    "          a=torch.load(creaFile)\n",
    "          policy_parameters['update_rule']=a['policy_parameters']['update_rule']\n",
    "          for k in policy_parameters['update_rule'].keys():\n",
    "\n",
    "\n",
    "            if(k!='R' and k!='T'):\n",
    "\n",
    "              policy_parameters['update_rule'][k]=policy_parameters['update_rule'][k][list_kernels]\n",
    "            policy_parameters['update_rule'][k]=policy_parameters['update_rule'][k].to('cuda')\n",
    "          clear_output(wait=False)\n",
    "          data_url=data[6:]\n",
    "          data_split=data_url.split(',')\n",
    "          system.config.final_step=int(data[1:5])\n",
    "\n",
    "\n",
    "      if(data[0]=='0'):\n",
    "        break\n",
    "      else:\n",
    "        data_url=data[6:]\n",
    "        data_split=data_url.split(',')\n",
    "        system.config.final_step=int(data[1:5])\n",
    "        for i in range(10):\n",
    "          policy_parameters['update_rule']['h'][i]=float(data_split[i*13])\n",
    "          policy_parameters['update_rule']['m'][i]=float(data_split[i*13+1])\n",
    "          policy_parameters['update_rule']['s'][i]=float(data_split[i*13+2])\n",
    "          policy_parameters['update_rule']['r'][i]=float(data_split[i*13+3])\n",
    "          policy_parameters['update_rule']['rk'][i][0]=float(data_split[i*13+4])\n",
    "          policy_parameters['update_rule']['rk'][i][1]=float(data_split[i*13+5])\n",
    "          policy_parameters['update_rule']['rk'][i][2]=float(data_split[i*13+6])\n",
    "          policy_parameters['update_rule']['w'][i][0]=float(data_split[i*13+7])\n",
    "          policy_parameters['update_rule']['w'][i][1]=float(data_split[i*13+8])\n",
    "          policy_parameters['update_rule']['w'][i][2]=float(data_split[i*13+9])\n",
    "          policy_parameters['update_rule']['b'][i][0]=float(data_split[i*13+10])\n",
    "          policy_parameters['update_rule']['b'][i][1]=float(data_split[i*13+11])\n",
    "          policy_parameters['update_rule']['b'][i][2]=float(data_split[i*13+12])\n",
    "\n",
    "      system.reset(initialization_parameters=policy_parameters['initialization'],update_rule_parameters=policy_parameters['update_rule'])\n",
    "      # print(data_url)\n",
    "\n",
    "      binary = b64decode(data_split[-1])\n",
    "      with open(\"laby.png\", 'wb') as f:\n",
    "        f.write(binary)\n",
    "      img = Image.open('laby.png')\n",
    "      img=np.array(img)\n",
    "\n",
    "      # plt.imshow(img[:,:,:3])\n",
    "      # plt.show()\n",
    "      # plt.imshow(img[:,:,-1])\n",
    "      # plt.show()\n",
    "      # if(img[0,0,1]>100):\n",
    "      #   break\n",
    "\n",
    "      if(np.all(img[:,:,0]<240)):\n",
    "        print(\"you didn't put the creature, creature put automatically in the bottom right corner\")\n",
    "      else:\n",
    "        system.init_loca=[]\n",
    "        for i in range(1,SX-40):\n",
    "          for j in range(1,SY-40):\n",
    "              if(img[i,j,0]>240 and img[i-1,j,0]<240 and img[i,j-1,0]<240 and img[i+1,j,0]>240 and img[i,j+1,0]>240):\n",
    "                system.init_loca.append((i,j))\n",
    "\n",
    "      img=((img[:,:,-1]>0).astype(np.float)-(img[:,:,0]>240).astype(np.float))\n",
    "\n",
    "      system.init_wall=torch.tensor(img)\n",
    "\n",
    "    if(mode=='random'):\n",
    "      nb_obstacle=int(input(\"number of obstacles (100 is interesting) \"))\n",
    "      radius_obstacle=int(input(\"radius of obstacles (10 is good)  \"))\n",
    "      system.random_obstacle(nb_obstacle,radius_obstacle)\n",
    "\n",
    "    if(borders):\n",
    "      system.init_wall[:,:4]=1\n",
    "      system.init_wall[:,-4:]=1\n",
    "      system.init_wall[-4:,:]=1\n",
    "      system.init_wall[:4,:]=1\n",
    "    print('Lenia running')\n",
    "    time_b=time.time()\n",
    "    with torch.no_grad():\n",
    "      system.generate_init_state()\n",
    "      system.state[0,:,:,0]=0\n",
    "      print(system.init_loca)\n",
    "      for loca in system.init_loca:\n",
    "          system.state[0,loca[0]:loca[0]+init_f.shape[0],loca[1]:loca[1]+init_f.shape[1],0]=init_f\n",
    "      observations = system.run()\n",
    "\n",
    "    print('Creating video')\n",
    "\n",
    "    time_lenia=time.time()-time_b\n",
    "\n",
    "    cmap = cm.get_cmap('jet')\n",
    "    with VideoWriter(\"out.mp4\", 30.0) as vid:\n",
    "      for timestep in range(observations[\"states\"].shape[0]):\n",
    "\n",
    "        # rgb_im = im_from_array_with_colormap(a[\"states\"][timestep,:,:,0].detach().cpu().numpy(), colormap)\n",
    "        # rgb_im = np.array(rgb_im.convert(\"RGB\"))\n",
    "        # rgb_arr = np.array(rgb_im.convert(\"RGB\"))\n",
    "        # print(a[\"states\"][timestep,:,:,0].detach().cpu().unsqueeze(-1).numpy().repeat(2,2).shape)\n",
    "\n",
    "\n",
    "\n",
    "        rgb_im=np.concatenate([observations[\"states\"][timestep,:,:,0].detach().cpu().unsqueeze(-1).numpy().repeat(2,2),observations[\"states\"][timestep,:,:,1].detach().cpu().unsqueeze(-1).numpy()],axis=2)\n",
    "        # rgb_im=cmap(observations[\"states\"][timestep,:,:,0].detach().cpu().numpy())[:,:,:3]\n",
    "        # rgb_im=np.clip(rgb_im-observations[\"states\"][timestep,:,:,1].detach().cpu().unsqueeze(-1).numpy(),0,1)\n",
    "        vid.add(rgb_im)\n",
    "      clear_output(wait=False)\n",
    "      print(policy_parameters['update_rule'])\n",
    "      vid.show()\n",
    "\n",
    "    cmap = cm.get_cmap('magma')\n",
    "    # for i in range(10):\n",
    "    #   with VideoWriter(\"out.mp4\", 30.0) as vid:\n",
    "    #     for timestep in range(observations[\"states\"].shape[0]):\n",
    "    #       # print(observations[\"kernels\"][i].shape)\n",
    "    #       # rgb_im=(observations[\"kernels\"][timestep,i].detach().cpu().unsqueeze(-1).numpy().repeat(3,2))\n",
    "    #       rgb_im=cmap(observations[\"kernels\"][timestep,i].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    #       # print(rgb_im.shape)\n",
    "    #       vid.add(rgb_im[:,:,:3])\n",
    "    #     vid.show()\n",
    "    # with VideoWriter(\"out.mp4\", 30.0) as vid:\n",
    "    #     for timestep in range(observations[\"states\"].shape[0]):\n",
    "    #       # print(observations[\"kernels\"][i].shape)\n",
    "    #       rgb_im=(observations[\"growth\"][timestep].detach().cpu().unsqueeze(-1).numpy().repeat(3,2))\n",
    "    #       # rgb_im=cmap(observations[\"kernels\"][timestep,i].detach().cpu().numpy())\n",
    "\n",
    "\n",
    "    #       # print(rgb_im.shape)\n",
    "    #       vid.add(rgb_im[:,:,:3])\n",
    "    #     vid.show()\n",
    "\n",
    "    if(modeb=='growth' or modeb=='both'):\n",
    "      observations[\"kernels\"][0,:,:,:]=-1\n",
    "      observations[\"growth\"][0,:,:]=0\n",
    "      min=torch.min(observations[\"kernels\"])\n",
    "      max=torch.max(observations[\"kernels\"])\n",
    "      observations[\"kernels\"]=(observations[\"kernels\"]-min)/(max-min)\n",
    "      colorbar=np.linspace(0,1,4*SX)\n",
    "      colorbar=np.expand_dims(colorbar,-1)\n",
    "      colorbar=colorbar.repeat(50,axis=-1)\n",
    "      colorbar=cmap(colorbar)[:,:,:3]\n",
    "      colorbar=cv2.putText(colorbar, #numpy array on which text is written\n",
    "                str(round(max.item(),3)), #text\n",
    "                (17,4*SX-10), #position at which writing has to start\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "                0.3, #font size\n",
    "                (0, 0,0, 255), #font color\n",
    "                1)\n",
    "      colorbar=cv2.putText(colorbar, #numpy array on which text is written\n",
    "                str(0), #text\n",
    "                (17,2*SX), #position at which writing has to start\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "                0.3, #font size\n",
    "                (209, 80, 250, 255), #font color\n",
    "                1) #font stroke\n",
    "      colorbar=cv2.putText(colorbar, #numpy array on which text is written\n",
    "                str(round(min.item(),3)), #text\n",
    "                (17,15), #position at which writing has to start\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "                0.3, #font size\n",
    "                (209, 80, 250, 255), #font color\n",
    "                1).get().astype('f') #font stroke\n",
    "\n",
    "      with VideoWriter(\"out.mp4\", 30.0) as vid:\n",
    "        for timestep in range(observations[\"states\"].shape[0]):\n",
    "          im=np.concatenate([observations[\"states\"][timestep,:,:,0].detach().cpu().unsqueeze(-1).numpy().repeat(2,2),observations[\"states\"][timestep,:,:,1].detach().cpu().unsqueeze(-1).numpy()],axis=2)\n",
    "          kern=cmap(observations[\"kernels\"][timestep,:,:,:].detach().cpu().numpy())[:,:,:,:3]\n",
    "          growth=(observations[\"growth\"][timestep].detach().cpu().unsqueeze(-1).numpy().repeat(3,2))\n",
    "          rgb_im=np.zeros((4*SX,3*SY,3))\n",
    "          for i in range(10):\n",
    "            position = (10,50)\n",
    "            kern[i]=cv2.putText(kern[i], #numpy array on which text is written\n",
    "                \"h= \"+str(round(policy_parameters['update_rule']['h'][i].item(),3))+ \" m = \"+str(round(policy_parameters['update_rule']['m'][i].item(),3))+\" s = \"+str(round(policy_parameters['update_rule']['s'][i].item(),3) ), #text\n",
    "                position, #position at which writing has to start\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "                0.3, #font size\n",
    "                (209, 80, 250, 255), #font color\n",
    "                1).get().astype('f') #font stroke\n",
    "            kern[i][img>0.5]=[0,0,1]\n",
    "            growth[img>0.5]=[0,0,1]\n",
    "\n",
    "          for i in range(3):\n",
    "            rgb_im[:SX,i*SY:(i+1)*SY]=kern[i]\n",
    "          rgb_im[SX:2*SX,:SY]=kern[3]\n",
    "          rgb_im[SX:2*SX,SY:2*SY]=im\n",
    "          rgb_im[SX:2*SX,2*SY:3*SY]=kern[4]\n",
    "          rgb_im[2*SX:3*SX,:SY]=kern[5]\n",
    "          rgb_im[2*SX:3*SX,SY:2*SY]=growth\n",
    "          rgb_im[2*SX:3*SX,2*SY:3*SY]=kern[6]\n",
    "          for i in range(3):\n",
    "            rgb_im[3*SX:4*SX,i*SY:(i+1)*SY]=kern[7+i]\n",
    "          rgb_im=np.concatenate([rgb_im,colorbar],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "          vid.add(rgb_im)\n",
    "        vid.show()\n",
    "    if(modeb=='sum' or modeb=='both'):\n",
    "      observations[\"kernel_neighb\"][0,:,:,:]=0\n",
    "      observations[\"growth\"][0,:,:]=0\n",
    "      min=torch.min(observations[\"kernel_neighb\"])\n",
    "      max=torch.max(observations[\"kernel_neighb\"])\n",
    "      observations[\"kernel_neighb\"]=(observations[\"kernel_neighb\"]-min)/(max-min)\n",
    "      colorbar=np.linspace(0,1,4*SX)\n",
    "      colorbar=np.expand_dims(colorbar,-1)\n",
    "      colorbar=colorbar.repeat(50,axis=-1)\n",
    "      colorbar=cmap(colorbar)[:,:,:3]\n",
    "      colorbar=cv2.putText(colorbar, #numpy array on which text is written\n",
    "                str(round(max.item(),3)), #text\n",
    "                (17,4*SX-10), #position at which writing has to start\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "                0.3, #font size\n",
    "                (0, 0,0, 255), #font color\n",
    "                1)\n",
    "      colorbar=cv2.putText(colorbar, #numpy array on which text is written\n",
    "                str(round(min.item(),3)), #text\n",
    "                (17,15), #position at which writing has to start\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "                0.3, #font size\n",
    "                (209, 80, 250, 255), #font color\n",
    "                1).get().astype('f') #font stroke\n",
    "      with VideoWriter(\"out.mp4\", 30.0) as vid:\n",
    "        for timestep in range(observations[\"states\"].shape[0]):\n",
    "          im=np.concatenate([observations[\"states\"][timestep,:,:,0].detach().cpu().unsqueeze(-1).numpy().repeat(2,2),observations[\"states\"][timestep,:,:,1].detach().cpu().unsqueeze(-1).numpy()],axis=2)\n",
    "          kern=cmap(observations[\"kernel_neighb\"][timestep,:,:,:].detach().cpu().numpy())[:,:,:,:3]\n",
    "          growth=((policy_parameters['update_rule']['h'].unsqueeze(-1).unsqueeze(-1)*observations[\"kernel_neighb\"][timestep,:,:,:]).sum(0).detach().cpu().unsqueeze(-1).numpy().repeat(3,2))\n",
    "          rgb_im=np.zeros((4*SX,3*SY,3))\n",
    "          for i in range(10):\n",
    "            position = (10,50)\n",
    "            kern[i][img>0.5]=[0,0,1]\n",
    "\n",
    "            kern[i]=cv2.putText(kern[i], #numpy array on which text is written\n",
    "                \"h= \"+str(round(policy_parameters['update_rule']['h'][i].item(),3))+ \" m = \"+str(round(policy_parameters['update_rule']['m'][i].item(),3))+\" s = \"+str(round(policy_parameters['update_rule']['s'][i].item(),3) ), #text\n",
    "                position, #position at which writing has to start\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, #font family\n",
    "                0.3, #font size\n",
    "                (209, 80, 250, 255), #font color\n",
    "                1).get().astype('f') #font stroke\n",
    "\n",
    "          for i in range(3):\n",
    "            rgb_im[:SX,i*SY:(i+1)*SY]=kern[i]\n",
    "          rgb_im[SX:2*SX,:SY]=kern[3]\n",
    "          rgb_im[SX:2*SX,SY:2*SY]=im\n",
    "          rgb_im[SX:2*SX,2*SY:3*SY]=kern[4]\n",
    "          rgb_im[2*SX:3*SX,:SY]=kern[5]\n",
    "          rgb_im[2*SX:3*SX,SY:2*SY]=growth\n",
    "          rgb_im[2*SX:3*SX,2*SY:3*SY]=kern[6]\n",
    "          for i in range(3):\n",
    "            rgb_im[3*SX:4*SX,i*SY:(i+1)*SY]=kern[7+i]\n",
    "\n",
    "          rgb_im=np.concatenate([rgb_im,colorbar],axis=1)\n",
    "\n",
    "\n",
    "\n",
    "          vid.add(rgb_im)\n",
    "        vid.show()\n",
    "    print(data)\n",
    "    print('computation of lenia took '+str(time_lenia))\n",
    "    if(mode=='random'):\n",
    "      break\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQZ5f635N-5t"
   },
   "source": [
    "## Systems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "_isAmhtCN-Pe"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LeniaInitializationSpace(DictSpace):\n",
    "    \"\"\" Class for initialization space that allows to sample and clip the initialization\"\"\"\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        default_config.neat_config = None\n",
    "        default_config.cppn_n_passes = 2\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self,init_size=40,  config={}, **kwargs):\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "\n",
    "        spaces = Dict(\n",
    "            # cppn_genome = LeniaCPPNInitSpace(self.config)\n",
    "            init=BoxSpace(low=0.0,high=1.0,shape=(init_size,init_size),mutation_mean=torch.zeros((40,40)),mutation_std=torch.ones((40,40))*0.01,indpb=0.0,dtype=torch.float32)\n",
    "        )\n",
    "\n",
    "        DictSpace.__init__(self, spaces=spaces)\n",
    "\n",
    "\n",
    "\n",
    "\"\"\" =============================================================================================\n",
    "Lenia Update Rule Space:\n",
    "============================================================================================= \"\"\"\n",
    "\n",
    "\n",
    "class LeniaUpdateRuleSpace(DictSpace):\n",
    "    \"\"\" Space associated to the parameters of the update rule\"\"\"\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self,nb_k=10, config={}, **kwargs):\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "\n",
    "        spaces = Dict(\n",
    "            R = DiscreteSpace(n=25, mutation_mean=0.0, mutation_std=0.01, indpb=0.01),\n",
    "            c0= MultiDiscreteSpace(nvec=[1]*nb_k, mutation_mean=torch.zeros((nb_k,)), mutation_std=0.1*torch.ones((nb_k,)), indpb=0.1),\n",
    "            c1= MultiDiscreteSpace(nvec=[1]*nb_k, mutation_mean=torch.zeros((nb_k,)), mutation_std=0.1*torch.ones((nb_k,)), indpb=0.1),\n",
    "            T = BoxSpace(low=1.0, high=10.0, shape=(), mutation_mean=0.0, mutation_std=0.1, indpb=0.01, dtype=torch.float32),\n",
    "            rk = BoxSpace(low=0, high=1, shape=(nb_k,3), mutation_mean=torch.zeros((nb_k,3)), mutation_std=0.2*torch.ones((nb_k,3)), indpb=1, dtype=torch.float32),\n",
    "            b = BoxSpace(low=0.0, high=1.0, shape=(nb_k,3), mutation_mean=torch.zeros((nb_k,3)), mutation_std=0.2*torch.ones((nb_k,3)), indpb=1, dtype=torch.float32),\n",
    "            w = BoxSpace(low=0.01, high=0.5, shape=(nb_k,3), mutation_mean=torch.zeros((nb_k,3)), mutation_std=0.2*torch.ones((nb_k,3)), indpb=1, dtype=torch.float32),\n",
    "            m = BoxSpace(low=0.05, high=0.5, shape=(nb_k,), mutation_mean=torch.zeros((nb_k,)), mutation_std=0.2*torch.ones((nb_k,)), indpb=1, dtype=torch.float32),\n",
    "            s = BoxSpace(low=0.001, high=0.18, shape=(nb_k,), mutation_mean=torch.zeros((nb_k,)), mutation_std=0.01**torch.ones((nb_k,)), indpb=0.1, dtype=torch.float32),\n",
    "            h = BoxSpace(low=0, high=1.0, shape=(nb_k,), mutation_mean=torch.zeros((nb_k,)), mutation_std=0.2*torch.ones((nb_k,)), indpb=0.1, dtype=torch.float32),\n",
    "            r = BoxSpace(low=0.2, high=1.0, shape=(nb_k,), mutation_mean=torch.zeros((nb_k,)), mutation_std=0.2*torch.ones((nb_k,)), indpb=1, dtype=torch.float32)\n",
    "            #kn = DiscreteSpace(n=4, mutation_mean=0.0, mutation_std=0.1, indpb=1.0),\n",
    "            #gn = DiscreteSpace(n=3, mutation_mean=0.0, mutation_std=0.1, indpb=1.0),\n",
    "        )\n",
    "\n",
    "        DictSpace.__init__(self, spaces=spaces)\n",
    "    def mutate(self,x):\n",
    "      mask=(x['s']>0.04).float()*(torch.rand(x['s'].shape[0])<0.25).float().to(x['s'].device)\n",
    "      param=[]\n",
    "      for k, space in self.spaces.items():\n",
    "        if(k==\"R\" or k==\"c0\" or k==\"c1\" or k==\"T\"):\n",
    "          param.append((k, space.mutate(x[k])))\n",
    "        elif(k=='rk' or k=='w' or k=='b'):\n",
    "          param.append((k, space.mutate(x[k],mask.unsqueeze(-1))))\n",
    "        else:\n",
    "          param.append((k, space.mutate(x[k],mask)))\n",
    "\n",
    "      return Dict(param)\n",
    "\n",
    "\n",
    "\"\"\" =============================================================================================\n",
    "Lenia Main\n",
    "============================================================================================= \"\"\"\n",
    "\n",
    "bell = lambda x, m, s: torch.exp(-((x-m)/s)**2 / 2)\n",
    "# Lenia family of functions for the kernel K and for the growth mapping g\n",
    "kernel_core = {\n",
    "    0: lambda u: (4 * u * (1 - u)) ** 4,  # polynomial (quad4)\n",
    "    1: lambda u: torch.exp(4 - 1 / (u * (1 - u))),  # exponential / gaussian bump (bump4)\n",
    "    2: lambda u, q=1 / 4: (u >= q).float() * (u <= 1 - q).float(),  # step (stpz1/4)\n",
    "    3: lambda u, q=1 / 4: (u >= q).float() * (u <= 1 - q).float() + (u < q).float() * 0.5,  # staircase (life)\n",
    "    4: lambda u: torch.exp(-(u-0.5)**2/0.2),\n",
    "    8: lambda u: (torch.sin(10*u)+1)/2,\n",
    "    9: lambda u: (a*torch.sin((u.unsqueeze(-1)*5*b+c)*np.pi)).sum(-1)/(2*a.sum())+1/2\n",
    "\n",
    "}\n",
    "field_func = {\n",
    "    0: lambda n, m, s: torch.max(torch.zeros_like(n), 1 - (n - m) ** 2 / (9 * s ** 2)) ** 4 * 2 - 1, # polynomial (quad4)\n",
    "    1: lambda n, m, s: torch.exp(- (n - m) ** 2 / (2 * s ** 2)-1e-3) * 2 - 1,  # exponential / gaussian (gaus)\n",
    "    2: lambda n, m, s: (torch.abs(n - m) <= s).float() * 2 - 1 , # step (stpz)\n",
    "    3: lambda n, m, s: - torch.clamp(n-m,0,1)*s #food eating kernl\n",
    "}\n",
    "\n",
    "# ker_c =lambda r,a,b,c :(a*torch.sin((r.unsqueeze(-1)*5*b+c)*np.pi)).sum(-1)/(2*a.sum())+1/2\n",
    "ker_c= lambda x,r,w,b : (b*torch.exp(-((x.unsqueeze(-1)-r)/w)**2 / 2)).sum(-1)\n",
    "\n",
    "class Dummy_init_mod(torch.nn.Module):\n",
    "  def __init__(self,init):\n",
    "    torch.nn.Module.__init__(self)\n",
    "    self.register_parameter('init', torch.nn.Parameter(init))\n",
    "\n",
    "\n",
    "# Lenia Step FFT version (faster)\n",
    "class LeniaStepFFTC(torch.nn.Module):\n",
    "    \"\"\" Module pytorch that computes one Lenia Step with the fft version\"\"\"\n",
    "\n",
    "    def __init__(self,C, R, T,c0,c1,r,rk, b,w,h, m, s, gn, is_soft_clip=False, SX=256, SY=256,speed_x=0,speed_y=0, device='cpu'):\n",
    "        torch.nn.Module.__init__(self)\n",
    "\n",
    "        self.register_buffer('R', R)\n",
    "        self.register_buffer('T', T)\n",
    "        self.register_buffer('c0', c0)\n",
    "        self.register_buffer('c1', c1)\n",
    "        # self.register_buffer('r', r)\n",
    "        self.register_parameter('r', torch.nn.Parameter(r))\n",
    "        self.register_parameter('rk', torch.nn.Parameter(rk))\n",
    "        self.register_parameter('b', torch.nn.Parameter(b))\n",
    "        self.register_parameter('w', torch.nn.Parameter(w))\n",
    "        self.register_parameter('h', torch.nn.Parameter(h))\n",
    "        self.register_parameter('m', torch.nn.Parameter(m))\n",
    "        self.register_parameter('s', torch.nn.Parameter(s))\n",
    "        self.speed_x=speed_x\n",
    "        self.speed_y=speed_y\n",
    "\n",
    "        self.gn = 1\n",
    "        self.nb_k=c0.shape[0]\n",
    "\n",
    "        self.SX = SX\n",
    "        self.SY = SY\n",
    "\n",
    "        self.is_soft_clip = is_soft_clip\n",
    "        self.C=C\n",
    "\n",
    "        self.device = device\n",
    "        self.to(device)\n",
    "        self.kernels=torch.zeros((self.nb_k,self.SX,self.SY,2)).to(self.device)\n",
    "\n",
    "        self.compute_kernel()\n",
    "        self.compute_kernel_env()\n",
    "\n",
    "    def compute_kernel_env(self):\n",
    "      \"\"\" computes the kernel and the kernel FFT of the environnement from the parameters\"\"\"\n",
    "      x = torch.arange(self.SX).to(self.device)\n",
    "      y = torch.arange(self.SY).to(self.device)\n",
    "      xx = x.view(-1, 1).repeat(1, self.SY)\n",
    "      yy = y.repeat(self.SX, 1)\n",
    "      X = (xx - int(self.SX / 2)).float()\n",
    "      Y = (yy - int(self.SY / 2)).float()\n",
    "      D = torch.sqrt(X ** 2 + Y ** 2)/(4)\n",
    "      kernel = torch.sigmoid(-(D-1)*10) * ker_c(D,torch.tensor(np.array([0,0,0])).to(self.device),torch.tensor(np.array([0.5,0.1,0.1])).to(self.device),torch.tensor(np.array([1,0,0])).to(self.device))\n",
    "      kernel_sum = torch.sum(kernel)\n",
    "      kernel_norm = (kernel / kernel_sum)\n",
    "      #kernel_FFT = torch.rfft(kernel_norm, signal_ndim=2, onesided=False).to(self.device)\n",
    "      kernel_FFT= torch.fft.rfftn(kernel_norm, dim=(0,1)).to(self.device)\n",
    "\n",
    "      self.kernel_wall=kernel_FFT\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def compute_kernel(self):\n",
    "      \"\"\" computes the kernel and the kernel FFT of the learnable channels from the parameters\"\"\"\n",
    "      x = torch.arange(self.SX).to(self.device)\n",
    "      y = torch.arange(self.SY).to(self.device)\n",
    "      xx = x.view(-1, 1).repeat(1, self.SY)\n",
    "      yy = y.repeat(self.SX, 1)\n",
    "      X = (xx - int(self.SX / 2)).float()\n",
    "      Y = (yy - int(self.SY / 2)).float()\n",
    "      self.kernels=torch.zeros((self.nb_k,self.SX,self.SY//2+1)).to(self.device)\n",
    "\n",
    "\n",
    "      for i in range(self.nb_k):\n",
    "        # distance to center in normalized space\n",
    "        D = torch.sqrt(X ** 2 + Y ** 2)/ ((self.R+15)*self.r[i])\n",
    "\n",
    "        kernel = torch.sigmoid(-(D-1)*10) * ker_c(D,self.rk[i],self.w[i],self.b[i])\n",
    "        kernel_sum = torch.sum(kernel)\n",
    "\n",
    "\n",
    "        # normalization of the kernel\n",
    "        kernel_norm = (kernel / kernel_sum)\n",
    "        # plt.imshow(kernel_norm[0,0].detach().cpu()*100)\n",
    "        # plt.show()\n",
    "\n",
    "\n",
    "\n",
    "        # fft of the kernel\n",
    "        #kernel_FFT = torch.rfft(kernel_norm, signal_ndim=2, onesided=False).to(self.device)\n",
    "        kernel_FFT=torch.fft.rfftn(kernel_norm, dim=(0,1)).to(self.device)\n",
    "\n",
    "        self.kernels[i]=kernel_FFT\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, input):\n",
    "        input[:,:,:,1]=torch.roll(input[:,:,:,1],[self.speed_y,self.speed_x],[1,2])\n",
    "        self.D=torch.zeros(input.shape).to(self.device)\n",
    "        self.Dn=torch.zeros(self.C)\n",
    "\n",
    "        #world_FFT = [torch.rfft(input[:,:,:,i], signal_ndim=2, onesided=False) for i in range(self.C)]\n",
    "        world_FFT = [torch.fft.rfftn(input[:,:,:,i], dim=(1,2)) for i in range(self.C)]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ## speed up of the update for 1 channel creature by multiplying by all the kernel FFT\n",
    "\n",
    "        #channel 0 is the learnable channel\n",
    "        world_FFT_c = world_FFT[0]\n",
    "        #multiply the FFT of the world and the kernels\n",
    "        potential_FFT = self.kernels* world_FFT_c\n",
    "        #ifft + realignself.SY//2+1\n",
    "        potential = torch.fft.irfftn(potential_FFT, dim=(1,2))\n",
    "        potential = roll_n(potential, 2, potential.size(2) // 2)\n",
    "        potential = roll_n(potential, 1, potential.size(1) // 2)\n",
    "        #growth function\n",
    "        gfunc = field_func[min(self.gn, 3)]\n",
    "        field = gfunc(potential, self.m.unsqueeze(-1).unsqueeze(-1), self.s.unsqueeze(-1).unsqueeze(-1))\n",
    "        #add the growth multiplied by the weight of the rule to the total growth\n",
    "        self.D[:,:,:,0]=(self.h.unsqueeze(-1).unsqueeze(-1)*field).sum(0,keepdim=True)\n",
    "        self.Dn[0]=self.h.sum()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        ###Base version for the case where we want the learnable creature to be  multi channel (which is not used in this notebook)\n",
    "\n",
    "        # for i in range(self.nb_k):\n",
    "        #   c0b=int((self.c0[i]))\n",
    "        #   c1b=int((self.c1[i]))\n",
    "\n",
    "        #   world_FFT_c = world_FFT[c0b]\n",
    "        #   potential_FFT = complex_mult_torch(self.kernels[i].unsqueeze(0), world_FFT_c)\n",
    "\n",
    "        #   potential = torch.irfft(potential_FFT, signal_ndim=2, onesided=False)\n",
    "        #   potential = roll_n(potential, 2, potential.size(2) // 2)\n",
    "        #   potential = roll_n(potential, 1, potential.size(1) // 2)\n",
    "\n",
    "\n",
    "        #   gfunc = field_func[min(self.gn, 3)]\n",
    "        #   field = gfunc(potential, self.m[i], self.s[i])\n",
    "\n",
    "        #   self.D[:,:,:,c1b]=self.D[:,:,:,c1b]+self.h[i]*field\n",
    "        #   self.Dn[c1b]=self.Dn[c1b]+self.h[i]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        #apply wall\n",
    "        world_FFT_c = world_FFT[self.C-1]\n",
    "        potential_FFT = self.kernel_wall* world_FFT_c\n",
    "        potential = torch.fft.irfftn(potential_FFT, dim=(1,2))\n",
    "        potential = roll_n(potential, 2, potential.size(2) // 2)\n",
    "        potential = roll_n(potential, 1, potential.size(1) // 2)\n",
    "        gfunc = field_func[3]\n",
    "        field = gfunc(potential, 1e-8, 10)\n",
    "        for i in range(self.C-1):\n",
    "          c1b=i\n",
    "          self.D[:,:,:,c1b]=self.D[:,:,:,c1b]+1*field\n",
    "          self.Dn[c1b]=self.Dn[c1b]+1\n",
    "\n",
    "\n",
    "        ## Add the total growth to the current state\n",
    "        if not self.is_soft_clip:\n",
    "\n",
    "            output_img = torch.clamp(input + (1.0 / self.T) * self.D, min=0., max=1.)\n",
    "            # output_img = input + (1.0 / self.T) * ((self.D/self.Dn+1)/2-input)\n",
    "\n",
    "        else:\n",
    "            output_img = torch.sigmoid((input + (1.0 / self.T) * self.D-0.5)*10)\n",
    "             # output_img = torch.tanh(input + (1.0 / self.T) * self.D)\n",
    "\n",
    "\n",
    "        return output_img\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class Lenia_C(torch.nn.Module):\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        default_config.version = 'pytorch_fft'  # \"pytorch_fft\", \"pytorch_conv2d\"\n",
    "        default_config.SX = 256\n",
    "        default_config.SY = 256\n",
    "        default_config.final_step = 40\n",
    "        default_config.C = 2\n",
    "        default_config.speed_x=0\n",
    "        default_config.speed_y=0\n",
    "        return default_config\n",
    "\n",
    "\n",
    "    def __init__(self, initialization_space=None, update_rule_space=None, nb_k=10,init_size=40, config={}, device=torch.device('cpu'), **kwargs):\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "        torch.nn.Module.__init__(self)\n",
    "        self.device = device\n",
    "        self.init_size=init_size\n",
    "        if initialization_space is not None:\n",
    "            self.initialization_space = initialization_space\n",
    "        else:\n",
    "            self.initialization_space = LeniaInitializationSpace(self.init_size)\n",
    "\n",
    "        if update_rule_space is not None:\n",
    "            self.update_rule_space = update_rule_space\n",
    "        else:\n",
    "            self.update_rule_space = LeniaUpdateRuleSpace(nb_k)\n",
    "\n",
    "        self.run_idx = 0\n",
    "        self.init_wall=torch.zeros((self.config.SX,self.config.SY))\n",
    "        #reset with no argument to sample random parameters\n",
    "        self.reset()\n",
    "        self.to(self.device)\n",
    "\n",
    "\n",
    "    def reset(self, initialization_parameters=None, update_rule_parameters=None):\n",
    "        # call the property setters\n",
    "        if(initialization_parameters is not None):\n",
    "          self.initialization_parameters = initialization_parameters\n",
    "        else:\n",
    "          self.initialization_parameters = self.initialization_space.sample()\n",
    "\n",
    "        if(update_rule_parameters is not None):\n",
    "          self.update_rule_parameters = update_rule_parameters\n",
    "        else:\n",
    "          policy_parameters = Dict.fromkeys(['update_rule'])\n",
    "          policy_parameters['update_rule'] = self.update_rule_space.sample()\n",
    "          #divide h by 3 at the beginning as some unbalanced kernels can easily kill\n",
    "          policy_parameters['update_rule'].h =policy_parameters['update_rule'].h/3\n",
    "          self.update_rule_parameters = policy_parameters['update_rule']\n",
    "\n",
    "        # initialize Lenia CA with update rule parameters\n",
    "        if self.config.version == \"pytorch_fft\":\n",
    "            lenia_step = LeniaStepFFTC(self.config.C,self.update_rule_parameters['R'], self.update_rule_parameters['T'],self.update_rule_parameters['c0'],self.update_rule_parameters['c1'], self.update_rule_parameters['r'], self.update_rule_parameters['rk'], self.update_rule_parameters['b'], self.update_rule_parameters['w'],self.update_rule_parameters['h'], self.update_rule_parameters['m'],self.update_rule_parameters['s'],1, is_soft_clip=False, SX=self.config.SX, SY=self.config.SY,\n",
    "                                       speed_x=self.config.speed_x,speed_y=self.config.speed_y, device=self.device)\n",
    "        self.add_module('lenia_step', lenia_step)\n",
    "\n",
    "        # initialize Lenia initial state with initialization_parameters\n",
    "        init = self.initialization_parameters['init']\n",
    "        # initialization_cppn = pytorchneat.rnn.RecurrentNetwork.create(cppn_genome, self.initialization_space.config.neat_config, device=self.device)\n",
    "        self.add_module('initialization', Dummy_init_mod(init))\n",
    "\n",
    "        # push the nn.Module and the available device\n",
    "        self.to(self.device)\n",
    "        self.generate_init_state()\n",
    "\n",
    "    def  random_obstacle(self,nb_obstacle=6):\n",
    "      self.init_wall=torch.zeros((self.config.SX,self.config.SY))\n",
    "\n",
    "      x = torch.arange(self.config.SX)\n",
    "      y = torch.arange(self.config.SY)\n",
    "      xx = x.view(-1, 1).repeat(1, self.config.SY)\n",
    "      yy = y.repeat(self.config.SX, 1)\n",
    "      for i in range(nb_obstacle):\n",
    "        X = (xx - int(torch.rand(1)*self.config.SX )).float()\n",
    "        Y = (yy - int(torch.rand(1)*self.config.SY/2)).float()\n",
    "        D = torch.sqrt(X ** 2 + Y ** 2)/10\n",
    "        mask=(D<1).float()\n",
    "        self.init_wall=torch.clamp(self.init_wall+mask,0,1)\n",
    "\n",
    "    def  random_obstacle_bis(self,nb_obstacle=6):\n",
    "      self.init_wall=torch.zeros((self.config.SX,self.config.SY))\n",
    "\n",
    "      x = torch.arange(self.config.SX)\n",
    "      y = torch.arange(self.config.SY)\n",
    "      xx = x.view(-1, 1).repeat(1, self.config.SY)\n",
    "      yy = y.repeat(self.config.SX, 1)\n",
    "      for i in range(nb_obstacle):\n",
    "        X = (xx - int(torch.rand(1)*self.config.SX )).float()\n",
    "        Y = (yy - int(torch.rand(1)*self.config.SY)).float()\n",
    "        D = torch.sqrt(X ** 2 + Y ** 2)/10\n",
    "        mask=(D<1).float()\n",
    "        self.init_wall=torch.clamp(self.init_wall+mask,0,1)\n",
    "      self.init_wall[95:155,170:230]=0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def generate_init_state(self,X=105,Y=180):\n",
    "        init_state = torch.zeros( 1,self.config.SX, self.config.SY,self.config.C, dtype=torch.float64)\n",
    "        init_state[0,X:X+self.init_size,Y:Y+self.init_size,0]=self.initialization.init\n",
    "        if(self.config.C>1):\n",
    "          init_state[0,:,:,1]=self.init_wall\n",
    "        self.state = init_state.to(self.device)\n",
    "        self.step_idx = 0\n",
    "\n",
    "\n",
    "    def update_initialization_parameters(self):\n",
    "        new_initialization_parameters = deepcopy(self.initialization_parameters)\n",
    "        new_initialization_parameters['init'] = self.initialization.init.data\n",
    "        if not self.initialization_space.contains(new_initialization_parameters):\n",
    "            new_initialization_parameters = self.initialization_space.clamp(new_initialization_parameters)\n",
    "            warnings.warn('provided parameters are not in the space range and are therefore clamped')\n",
    "        self.initialization_parameters = new_initialization_parameters\n",
    "\n",
    "    def update_update_rule_parameters(self):\n",
    "        new_update_rule_parameters = deepcopy(self.update_rule_parameters)\n",
    "        #gather the parameter from the lenia step (which may have been optimized)\n",
    "        new_update_rule_parameters['m'] = self.lenia_step.m.data\n",
    "        new_update_rule_parameters['s'] = self.lenia_step.s.data\n",
    "        new_update_rule_parameters['r'] = self.lenia_step.r.data\n",
    "        new_update_rule_parameters['rk'] = self.lenia_step.rk.data\n",
    "        new_update_rule_parameters['b'] = self.lenia_step.b.data\n",
    "        new_update_rule_parameters['w'] = self.lenia_step.w.data\n",
    "        new_update_rule_parameters['h'] = self.lenia_step.h.data\n",
    "        if not self.update_rule_space.contains(new_update_rule_parameters):\n",
    "            new_update_rule_parameters = self.update_rule_space.clamp(new_update_rule_parameters)\n",
    "            warnings.warn('provided parameters are not in the space range and are therefore clamped')\n",
    "        self.update_rule_parameters = new_update_rule_parameters\n",
    "\n",
    "    def step(self, intervention_parameters=None):\n",
    "        self.state = self.lenia_step(self.state)\n",
    "        self.step_idx += 1\n",
    "        return self.state\n",
    "\n",
    "\n",
    "    def forward(self):\n",
    "        state = self.step(None)\n",
    "        return state\n",
    "\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\" run lenia for the number of step specified in the config.\n",
    "        Returns the observations containing the state at each timestep\"\"\"\n",
    "        #clip parameters just in case\n",
    "        if not self.initialization_space['init'].contains(self.initialization.init.data):\n",
    "          self.initialization.init.data = self.initialization_space['init'].clamp(self.initialization.init.data)\n",
    "        if not self.update_rule_space['r'].contains(self.lenia_step.r.data):\n",
    "            self.lenia_step.r.data = self.update_rule_space['r'].clamp(self.lenia_step.r.data)\n",
    "        if not self.update_rule_space['rk'].contains(self.lenia_step.rk.data):\n",
    "            self.lenia_step.rk.data = self.update_rule_space['rk'].clamp(self.lenia_step.rk.data)\n",
    "        if not self.update_rule_space['b'].contains(self.lenia_step.b.data):\n",
    "            self.lenia_step.b.data = self.update_rule_space['b'].clamp(self.lenia_step.b.data)\n",
    "        if not self.update_rule_space['w'].contains(self.lenia_step.w.data):\n",
    "            self.lenia_step.w.data = self.update_rule_space['w'].clamp(self.lenia_step.w.data)\n",
    "        if not self.update_rule_space['h'].contains(self.lenia_step.h.data):\n",
    "            self.lenia_step.h.data = self.update_rule_space['h'].clamp(self.lenia_step.h.data)\n",
    "        if not self.update_rule_space['m'].contains(self.lenia_step.m.data):\n",
    "            self.lenia_step.m.data = self.update_rule_space['m'].clamp(self.lenia_step.m.data)\n",
    "        if not self.update_rule_space['s'].contains(self.lenia_step.s.data):\n",
    "            self.lenia_step.s.data = self.update_rule_space['s'].clamp(self.lenia_step.s.data)\n",
    "        # self.generate_init_state()\n",
    "        observations = Dict()\n",
    "        observations.timepoints = list(range(self.config.final_step))\n",
    "        observations.states = torch.empty((self.config.final_step, self.config.SX, self.config.SY,self.config.C))\n",
    "        observations.states[0]  = self.state\n",
    "        for step_idx in range(1, self.config.final_step):\n",
    "            cur_observation = self.step(None)\n",
    "            observations.states[step_idx] = cur_observation[0,:,:,:]\n",
    "\n",
    "\n",
    "        return observations\n",
    "\n",
    "    def save(self, filepath):\n",
    "        \"\"\"\n",
    "        Saves the system object using torch.save function in pickle format\n",
    "        Can be used if the system state's change over exploration and we want to dump it\n",
    "        \"\"\"\n",
    "        torch.save(self, filepath)\n",
    "\n",
    "\n",
    "    def close(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oimkkOjkpic2"
   },
   "source": [
    "# Random rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 805
    },
    "id": "_CQqFBVWpnDB",
    "outputId": "41deae5b-20de-4bec-bd8e-9793e600031b"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'size'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[16], line 12\u001b[0m\n\u001b[1;32m     10\u001b[0m system\u001b[38;5;241m.\u001b[39mgenerate_init_state()\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# the method system.run() launches a rollout in Lenia\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m observations\u001b[38;5;241m=\u001b[39m\u001b[43msystem\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m VideoWriter(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout.mp4\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;241m30.0\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m vid:\n\u001b[1;32m     16\u001b[0m       \u001b[38;5;28;01mfor\u001b[39;00m timestep \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(observations[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstates\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n",
      "Cell \u001b[0;32mIn[15], line 455\u001b[0m, in \u001b[0;36mLenia_C.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    453\u001b[0m observations\u001b[38;5;241m.\u001b[39mstates[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n\u001b[1;32m    454\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m step_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;241m1\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mfinal_step):\n\u001b[0;32m--> 455\u001b[0m     cur_observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    456\u001b[0m     observations\u001b[38;5;241m.\u001b[39mstates[step_idx] \u001b[38;5;241m=\u001b[39m cur_observation[\u001b[38;5;241m0\u001b[39m,:,:,:]\n\u001b[1;32m    459\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m observations\n",
      "Cell \u001b[0;32mIn[15], line 419\u001b[0m, in \u001b[0;36mLenia_C.step\u001b[0;34m(self, intervention_parameters)\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, intervention_parameters\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m--> 419\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlenia_step\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    420\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_idx \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    421\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\n",
      "File \u001b[0;32m~/Documents/cpge/mp2/tipe-mp2/.venv/lib/python3.11/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[15], line 217\u001b[0m, in \u001b[0;36mLeniaStepFFTC.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    215\u001b[0m potential \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mfft\u001b[38;5;241m.\u001b[39mirfftn(potential_FFT, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m))\n\u001b[1;32m    216\u001b[0m potential \u001b[38;5;241m=\u001b[39m roll_n(potential, \u001b[38;5;241m2\u001b[39m, potential\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m2\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m--> 217\u001b[0m potential \u001b[38;5;241m=\u001b[39m roll_n(potential, \u001b[38;5;241m1\u001b[39m, \u001b[43mpotential\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msize\u001b[49m(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m/\u001b[39m\u001b[38;5;241m/\u001b[39m \u001b[38;5;241m2\u001b[39m)\n\u001b[1;32m    218\u001b[0m \u001b[38;5;66;03m#growth function\u001b[39;00m\n\u001b[1;32m    219\u001b[0m gfunc \u001b[38;5;241m=\u001b[39m field_func[\u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgn, \u001b[38;5;241m3\u001b[39m)]\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'size'"
     ]
    }
   ],
   "source": [
    "system=Lenia_C(nb_k=5)\n",
    "system.config.final_step=200\n",
    "\n",
    "with torch.no_grad():\n",
    "  for _ in range(4):\n",
    "    # the method system.reset() sets random parameters for Lenia update rule, unless update_rule_parameters are passed as argument\n",
    "    system.reset()\n",
    "    # the method system.generate_init_state() allows to generate a random intialization square in all channels (but you can replace it by setting yourself the system.state)\n",
    "    system.random_obstacle(0)\n",
    "    system.generate_init_state()\n",
    "    # the method system.run() launches a rollout in Lenia\n",
    "    observations=system.run()\n",
    "\n",
    "\n",
    "    with VideoWriter(\"out.mp4\", 30.0) as vid:\n",
    "          for timestep in range(observations[\"states\"].shape[0]):\n",
    "\n",
    "\n",
    "            rgb_im=observations.states[timestep,:,:,0].detach().cpu().numpy()\n",
    "\n",
    "            vid.add(rgb_im)\n",
    "          vid.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Teo-Z0yYZpVP"
   },
   "source": [
    "# Load trained creatures and test them by designing the env (obtained with the method from the blogpost)\n",
    "\n",
    "In this section, we display several creatures obtained with the technique given in the blogpost. Those creatures are robust to environmental perturbations.\n",
    "You can add walls and"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Yag-wm2TZtvs",
    "outputId": "a18f5bb1-3216-4e39-e07d-dd6f98d8d58e"
   },
   "outputs": [],
   "source": [
    "# 3 examples of discovered creatures (1 channel and 10 rules)\n",
    "\n",
    "!wget  'https://drive.google.com/uc?export=download&id=17GpsPKaksbgoV1nD0Camh0FPGZgLDeFV' -O 'crea1.pickle'\n",
    "!wget  'https://drive.google.com/uc?export=download&id=19eBYNItd-4OrQA_uG0o4a2XOBVGpeuih' -O 'crea2.pickle'\n",
    "!wget  'https://drive.google.com/uc?export=download&id=1h9g_j8xyV66QGOsoOswUUSHZhQse7IDH' -O 'crea3.pickle'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1jX06TSPkhj7"
   },
   "source": [
    "Changing the zoom, changes the size of the kernel (zoom from 0 to 1 ) allowing you to make the change of scale experiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "0eOkwgUYaTOl",
    "outputId": "a7e594aa-3c83-41d4-9c7f-5719ae457596"
   },
   "outputs": [],
   "source": [
    "#@title Main\n",
    "SY =  256#@param {type:\"integer\"}\n",
    "SX =  256#@param {type:\"integer\"}\n",
    "# timesteps =  200#@param {type:\"integer\"}\n",
    "mode = \"draw\" #@param [\"draw\", \"random\"]\n",
    "modeb = \"none\" #@param [\"growth\", \"sum\", \"none\", \"both\"]\n",
    "borders = False #@param {type:\"boolean\"}\n",
    "creature= \"crea1\"  #@param [\"crea1\",\"crea2\",\"crea3\"]\n",
    "main(SX,SY,mode,borders,[0,1,2,3,4,5,6,7,8,9],creaFile=creature+\".pickle\",modeb=modeb,zoom=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7BPqqGJA8nC0"
   },
   "source": [
    "# Run the method to learn the rules leading to emergent robust creatures.\n",
    "\n",
    "\n",
    "In this section you can run the method from the blogpost.\n",
    "\n",
    "If you want to try to find new creatures, don't run the seed cell below.\n",
    " There is no certainty to find perfect creature, you may find creatures that don't have individuality in the multi creature setting or even some might die from specific collision with walls.\n",
    "\n",
    "If you didn't run the seed cell, there is no certainty to find perfect creature, you may find creatures that don't have individuality in the multi creature setting or even some might die from specific collision with walls. Thus you may have to run this part few times before getting a very robust creature.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZituIpcR0WDP"
   },
   "source": [
    "##seed\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eHqb5U_Iompz",
    "outputId": "0c87b764-9935-4d19-eb66-7cf380b4dd28"
   },
   "outputs": [],
   "source": [
    "torch.manual_seed(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2PLWDzfmpDHL"
   },
   "source": [
    "## IMGEP code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Bc3vjVL8BM2"
   },
   "source": [
    "### output representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kCRFlCig7721"
   },
   "outputs": [],
   "source": [
    "class OutputRepresentation:\n",
    "    \"\"\" Base class to map the observations of a system to an embedding vector (BC characterization)\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, config={}, **kwargs):\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "\n",
    "    def calc(self, observations, **kwargs):\n",
    "        \"\"\" Maps the observations of a behavioral descriptor\n",
    "            Args:\n",
    "                observations (Dict): observations received after one environment run\n",
    "            Returns\n",
    "                embeddings (Dict): generally vector but we might need Dict structures, for instance for IMGEP-HOLMES\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def calc_distance(self, embedding_a, embedding_b, **kwargs):\n",
    "        \"\"\" Compute the distance between 2 embedding\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BgTzsE6j48_G"
   },
   "outputs": [],
   "source": [
    "class LeniaCentroidRepresentation(OutputRepresentation):\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = OutputRepresentation.default_config()\n",
    "        default_config.env_size = (256, 256)\n",
    "        default_config.distance_function = \"L2\"\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, config=None, **kwargs):\n",
    "        super().__init__(config=config, **kwargs)\n",
    "        self.n_latents = 3\n",
    "\n",
    "\n",
    "    def calc(self, observations):\n",
    "        \"\"\"\n",
    "            Maps the observations of a system to an embedding vector\n",
    "            Return a torch tensor\n",
    "        \"\"\"\n",
    "\n",
    "        # filter low values\n",
    "        filtered_im =observations.states[-1,:,:,0]\n",
    "\n",
    "        # recenter\n",
    "        mu_0 = filtered_im.sum()\n",
    "\n",
    "        # implementation of meshgrid in torch\n",
    "        x = torch.arange(self.config.env_size[0])\n",
    "        y = torch.arange(self.config.env_size[1])\n",
    "        yy = y.repeat(self.config.env_size[0], 1)\n",
    "        xx = x.view(-1, 1).repeat(1, self.config.env_size[1])\n",
    "\n",
    "        X = (xx - int(self.config.env_size[0] / 2)).double()\n",
    "        Y = (yy - int(self.config.env_size[1] / 2)).double()\n",
    "\n",
    "        centroid_x = ((X * filtered_im).sum() / (mu_0+1e-10))\n",
    "        centroid_y = ((Y * filtered_im).sum() / (mu_0+1e-10))\n",
    "        X = (xx -centroid_x-self.config.env_size[0] / 2).double()\n",
    "        Y = (yy - centroid_y-self.config.env_size[1] / 2).double()\n",
    "\n",
    "        # distance to center in normalized space\n",
    "        D = torch.sqrt(X ** 2 + Y ** 2)/ (35)\n",
    "\n",
    "        mask=0.85*(D<0.5).float()+0.15*(D<1).float()\n",
    "        loss=(filtered_im-0.9*mask).pow(2).sum().sqrt()\n",
    "\n",
    "        embedding = torch.zeros(3)\n",
    "        embedding[0]=loss/230\n",
    "        embedding[1]=centroid_x.mean()/self.config.env_size[0]\n",
    "        embedding[2]=centroid_y.mean()/self.config.env_size[1]\n",
    "        if(mu_0<1e-4):\n",
    "          embedding[1]=embedding[1]-10\n",
    "          embedding[2]=embedding[2]-10\n",
    "\n",
    "\n",
    "        # print(embedding)\n",
    "\n",
    "\n",
    "\n",
    "        return embedding\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def calc_distance(self, embedding_a, embedding_b):\n",
    "        \"\"\"\n",
    "            Compute the distance between 2 embeddings in the latent space\n",
    "            /!\\ batch mode embedding_a and embedding_b can be N*M or M\n",
    "        \"\"\"\n",
    "        # l2 loss\n",
    "        if self.config.distance_function == \"L2\":\n",
    "            dist = (embedding_a - embedding_b).pow(2).sum(-1).sqrt()\n",
    "\n",
    "        else:\n",
    "            raise NotImplementedError\n",
    "\n",
    "        return dist"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "815hRpLz8Hm9"
   },
   "source": [
    "### IMGEP def"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "HsdfS6qa8KZm"
   },
   "outputs": [],
   "source": [
    "class Explorer:\n",
    "    \"\"\"\n",
    "    Base class for exploration experiments.\n",
    "    Allows to save and load exploration results\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, system, explorationdb, config={}, **kwargs):\n",
    "        self.config = self.__class__.default_config()\n",
    "        self.config.update(config)\n",
    "        self.config.update(kwargs)\n",
    "\n",
    "        self.system = system\n",
    "        self.db = explorationdb\n",
    "\n",
    "    def save(self, filepath):\n",
    "        \"\"\"\n",
    "        Saves the explorer object using torch.save function in pickle format\n",
    "        /!\\ We intentionally empty explorer.db from the pickle\n",
    "        because the database is already automatically saved in external files each time the explorer call self.db.add_run_data\n",
    "        \"\"\"\n",
    "        # do not pickle the data as already saved in extra files\n",
    "        tmp_data = self.db\n",
    "        self.db.reset_empty_db()\n",
    "\n",
    "        # pickle exploration object\n",
    "        torch.save(self, filepath)\n",
    "\n",
    "        # attach db again to the exploration object\n",
    "        self.db = tmp_data\n",
    "\n",
    "    @staticmethod\n",
    "    def load(explorer_filepath, load_data=True, run_ids=None, map_location='cuda'):\n",
    "\n",
    "        explorer = torch.load(explorer_filepath, map_location=map_location)\n",
    "\n",
    "        # loop over policy parameters to coalesce sparse tensors (not coalesced by default)\n",
    "        def coalesce_parameter_dict(d, has_coalesced_tensor=False):\n",
    "            for k, v in d.items():\n",
    "                if isinstance(v, Dict):\n",
    "                    d[k], has_coalesced_tensor = coalesce_parameter_dict(v, has_coalesced_tensor=has_coalesced_tensor)\n",
    "                elif isinstance(v, torch.Tensor) and v.is_sparse and not v.is_coalesced():\n",
    "                    d[k] = v.coalesce()\n",
    "                    has_coalesced_tensor = True\n",
    "            return d, has_coalesced_tensor\n",
    "\n",
    "        for policy_idx, policy in enumerate(explorer.policy_library):\n",
    "            explorer.policy_library[policy_idx], has_coalesced_tensor = coalesce_parameter_dict(policy)\n",
    "            if not has_coalesced_tensor:\n",
    "                break\n",
    "\n",
    "        if load_data:\n",
    "            explorer.db = ExplorationDB(config=explorer.db.config)\n",
    "            explorer.db.load(run_ids=run_ids, map_location=map_location)\n",
    "\n",
    "        return explorer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s7VfAVH5pH8H"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "class IMGEPExplorer(Explorer):\n",
    "    \"\"\"\n",
    "    Basic explorer that samples goals in a goalspace and uses a policy library to generate parameters to reach the goal.\n",
    "    \"\"\"\n",
    "\n",
    "    # Set these in ALL subclasses\n",
    "    goal_space = None  # defines the obs->goal representation and the goal sampling strategy (self.goal_space.sample())\n",
    "    reach_goal_optimizer = None\n",
    "\n",
    "    @staticmethod\n",
    "    def default_config():\n",
    "        default_config = Dict()\n",
    "        # base config\n",
    "        default_config.num_of_random_initialization = 40  # number of random runs at the beginning of exploration to populate the IMGEP memory\n",
    "\n",
    "        # Pi: source policy parameters config\n",
    "        default_config.source_policy_selection = Dict()\n",
    "        default_config.source_policy_selection.type = 'optimal'  # either: 'optimal', 'random'\n",
    "\n",
    "        # Opt: Optimizer to reach goal\n",
    "        default_config.reach_goal_optimizer = Dict()\n",
    "        default_config.reach_goal_optimizer.optim_steps = 10\n",
    "        default_config.reach_goal_optimizer.name = \"SGD\"\n",
    "        default_config.reach_goal_optimizer.initialization_cppn.parameters.lr =  1e-3\n",
    "        default_config.reach_goal_optimizer.lenia_step.parameters.lr = 1e-4\n",
    "        # default_config.reach_goal_optimizer.parameters.eps=1e-4\n",
    "\n",
    "        return default_config\n",
    "\n",
    "    def __init__(self, system, explorationdb, goal_space, config={}, **kwargs):\n",
    "        super().__init__(system=system, explorationdb=explorationdb, config=config, **kwargs)\n",
    "\n",
    "        self.goal_space = goal_space\n",
    "\n",
    "        # initialize policy library\n",
    "        self.policy_library = []\n",
    "\n",
    "        # initialize goal library\n",
    "        self.goal_library = torch.empty((0,) + self.goal_space.shape)\n",
    "\n",
    "        # reach goal optimizer\n",
    "        self.reach_goal_optimizer = None\n",
    "\n",
    "    def get_source_policy_idx(self, target_goal):\n",
    "\n",
    "        if self.config.source_policy_selection.type == 'optimal':\n",
    "            # get distance to other goals\n",
    "            tbis=self.goal_library*1.0\n",
    "            #augment distance to creature that exploded or died because we don't want to select them.\n",
    "            tbis[:,1]=tbis[:,1]+(tbis[:,1]<-9).float()*100\n",
    "            tbis[:,1]=tbis[:,1]+(tbis[:,0]>0.11).float()*100\n",
    "            goal_distances = self.goal_space.calc_distance(target_goal.unsqueeze(0), tbis)\n",
    "            source_policy_idx = torch.argmin(goal_distances)\n",
    "\n",
    "        elif self.config.source_policy_selection.type == 'random':\n",
    "            source_policy_idx = sample_value(('discrete', 0, len(self.goal_library) - 1))\n",
    "\n",
    "        else:\n",
    "            raise ValueError('Unknown source policy selection type {!r} in the configuration!'.format(\n",
    "                self.config.source_policy_selection.type))\n",
    "\n",
    "        return source_policy_idx\n",
    "\n",
    "    def sample__interesting_goal(self):\n",
    "      \"\"\" Sample a target goal randomly but taking into account the goal already reached in order to not sample an area to close from an already reached zone or too far from what can be reached \"\"\"\n",
    "      # arbitrary sampling of goal, some other may be more efficient\n",
    "      close =0\n",
    "      veryclose=10\n",
    "      compt=0\n",
    "\n",
    "      #change distance for reached goal when the creature died or exploded\n",
    "      tbis=self.goal_library*1.0\n",
    "      tbis[:,2]=tbis[:,2]+(tbis[:,1]<-9).float()*100\n",
    "      tbis[:,2]=tbis[:,2]+(tbis[:,0]>0.11).float()*100\n",
    "\n",
    "\n",
    "\n",
    "      # loop until region not explored too much and also not too far\n",
    "      target_goal=torch.ones(3)*-10\n",
    "      while close<1 or veryclose>2:\n",
    "        target_goal[0]=0.065+torch.normal(torch.zeros(1))*0.002\n",
    "        if(torch.rand(1)<0.2):\n",
    "          #go a little further than previous best\n",
    "          ind=torch.argmin(tbis[:,2])\n",
    "          target_goal[1]=tbis[ind,1]+(torch.rand(1)*0.45-0.22)/4\n",
    "          target_goal[2]=tbis[ind,2]-0.04*torch.rand(1)-0.02\n",
    "\n",
    "        else:\n",
    "          # with high probability try far points\n",
    "            if(torch.rand(1)<0.7):\n",
    "              target_goal[2]=torch.rand(1)*0.2-0.35\n",
    "              target_goal[1]=-(torch.rand(1)*0.45-0.22)\n",
    "            else:\n",
    "              target_goal[2]=torch.rand(1)*0.35-0.35\n",
    "              target_goal[1]=-(torch.rand(1)*0.45-0.22)\n",
    "\n",
    "        goal_distances = self.goal_space.calc_distance(target_goal.unsqueeze(0), tbis)\n",
    "        close=(goal_distances<0.1).float().sum()\n",
    "        veryclose=(goal_distances<0.06).float().sum()\n",
    "        compt=compt+1\n",
    "      return(target_goal)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    def run(self, n_exploration_runs, continue_existing_run=False):\n",
    "\n",
    "      again =True\n",
    "      #while loop that sample new initialization and try until a good run is achieved,\n",
    "      #the run will start from a new initialization in some cases like not enough progress in a certain number of steps etc\n",
    "      while again :\n",
    "        print('NEW TRY OF INIT')\n",
    "\n",
    "\n",
    "        print('Exploration: ')\n",
    "        progress_bar = tqdm(total=n_exploration_runs)\n",
    "        if continue_existing_run:\n",
    "            run_idx = len(self.policy_library)\n",
    "            progress_bar.update(run_idx)\n",
    "        else:\n",
    "            self.policy_library = []\n",
    "            self.goal_library = torch.empty((0,) + self.goal_space.shape)\n",
    "            run_idx = 0\n",
    "        nb_alive_random=0\n",
    "\n",
    "        ############# Beginning of the search ##############\n",
    "        while run_idx < n_exploration_runs:\n",
    "            policy_parameters = Dict.fromkeys(\n",
    "                ['initialization', 'update_rule'])  # policy parameters (output of IMGEP policy)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ############ Initial Random Sampling of Parameters ####################\n",
    "            if len(self.policy_library) < self.config.num_of_random_initialization:\n",
    "\n",
    "                target_goal = None\n",
    "                source_policy_idx = None\n",
    "                reached_goal=torch.ones(19)\n",
    "\n",
    "                # sample new parameters to test\n",
    "                policy_parameters['initialization'] = self.system.initialization_space.sample()\n",
    "                policy_parameters['update_rule'] = self.system.update_rule_space.sample()\n",
    "                #divide h by 3 at the beginning as some unbalanced kernels can easily kill\n",
    "                policy_parameters['update_rule'].h =policy_parameters['update_rule'].h/3\n",
    "                self.system.reset(initialization_parameters=policy_parameters['initialization'],\n",
    "                update_rule_parameters=policy_parameters['update_rule'])\n",
    "\n",
    "                #run the system\n",
    "                with torch.no_grad():\n",
    "                    self.system.random_obstacle(8)\n",
    "                    self.system.generate_init_state()\n",
    "                    observations = self.system.run()\n",
    "                    reached_goal = self.goal_space.map(observations)\n",
    "                is_dead = reached_goal[0]>0.9 or reached_goal[1]<-0.5\n",
    "                if not is_dead:\n",
    "                    nb_alive_random=nb_alive_random+1\n",
    "\n",
    "                optim_step_idx = 0\n",
    "                dist_to_target = None\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            ############## Goal-directed Sampling of Parameters ######################\n",
    "            else:\n",
    "\n",
    "\n",
    "                # sample a goal space from the goal space\n",
    "\n",
    "                # for the first 8 target goal simply try to go as far as possible straight (each time goal a little bit further)\n",
    "                if(len(self.policy_library)-self.config.num_of_random_initialization<8):\n",
    "                  target_goal=torch.ones(3)*-10\n",
    "                  target_goal[0]=0.065\n",
    "                  target_goal[2]=0.19-(len(self.policy_library)-self.config.num_of_random_initialization)*0.06\n",
    "                  target_goal[1]=0\n",
    "                # then random goal in a region not reached but not too far\n",
    "                else:\n",
    "                  target_goal=self.sample__interesting_goal()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                if(len(self.policy_library)-self.config.num_of_random_initialization>=2):\n",
    "                  print(f'Run {run_idx}, optimisation toward goal: ')\n",
    "                  print(\"TARGET =\"+str(target_goal))\n",
    "\n",
    "\n",
    "                # get source policy for this target goal\n",
    "                source_policy_idx = self.get_source_policy_idx(target_goal)\n",
    "                source_policy = self.policy_library[source_policy_idx]\n",
    "\n",
    "\n",
    "                # if we're at the beginning or iteration%5==0 then don't mutate and train for longer\n",
    "                if(len(self.policy_library)-self.config.num_of_random_initialization<8 or len(self.policy_library)%5==0 ):\n",
    "\n",
    "                  policy_parameters['initialization'] = deepcopy(source_policy['initialization'])\n",
    "                  policy_parameters['update_rule'] = deepcopy(source_policy['update_rule'])\n",
    "                  self.system.reset(initialization_parameters=policy_parameters['initialization'],\n",
    "                                    update_rule_parameters=policy_parameters['update_rule'])\n",
    "                  ite=self.config.reach_goal_optimizer.optim_steps\n",
    "                # else mutate\n",
    "                else:\n",
    "                  ite=15\n",
    "                  # mutate until finding a non dying and non exploding creature\n",
    "                  die_mutate=True\n",
    "                  while die_mutate:\n",
    "                    policy_parameters['initialization'] = self.system.initialization_space.mutate(source_policy['initialization'])\n",
    "                    policy_parameters['update_rule'] = self.system.update_rule_space.mutate(source_policy['update_rule'])\n",
    "                    self.system.reset(initialization_parameters=policy_parameters['initialization'],\n",
    "                                      update_rule_parameters=policy_parameters['update_rule'])\n",
    "                    with torch.no_grad():\n",
    "                      self.system.generate_init_state()\n",
    "                      observations = self.system.run()\n",
    "                      reached_goal = self.goal_space.map(observations)\n",
    "                    # if doesn't not die or explode break the loop\n",
    "                    if observations.states[-1,:,:,0].sum()>10 or reached_goal[0]>0.11:\n",
    "                      die_mutate=False\n",
    "\n",
    "\n",
    "                ##### INNER LOOP (Optimization part toward target goal ) ####\n",
    "                if isinstance(self.system, torch.nn.Module) and self.config.reach_goal_optimizer.optim_steps > 0:\n",
    "\n",
    "\n",
    "                    optimizer_class = eval(f'torch.optim.{self.config.reach_goal_optimizer.name}')\n",
    "                    self.reach_goal_optimizer = optimizer_class([{'params': self.system.initialization.parameters(), **self.config.reach_goal_optimizer.initialization_cppn.parameters},\n",
    "                                                                {'params': self.system.lenia_step.parameters(), **self.config.reach_goal_optimizer.lenia_step.parameters}],\n",
    "                                                                **self.config.reach_goal_optimizer.parameters)\n",
    "\n",
    "                    last_dead=False\n",
    "                    for optim_step_idx in range(1, ite):\n",
    "\n",
    "                        # run system with IMGEP's policy parameters\n",
    "                        self.system.random_obstacle(8)\n",
    "                        self.system.generate_init_state()\n",
    "                        observations = self.system.run()\n",
    "                        reached_goal = self.goal_space.map(observations)\n",
    "\n",
    "                        ### Define  target disk\n",
    "                        x = torch.arange(self.system.config.SX)\n",
    "                        y = torch.arange(self.system.config.SY)\n",
    "                        xx = x.view(-1, 1).repeat(1, self.system.config.SY)\n",
    "                        yy = y.repeat(self.system.config.SX, 1)\n",
    "                        X = (xx -(target_goal[1]+0.5)*self.system.config.SX).float() / (35)\n",
    "                        Y = (yy - (target_goal[2]+0.5)*self.system.config.SY).float() / (35)\n",
    "                        # distance to center in normalized space\n",
    "                        D = torch.sqrt(X ** 2 + Y ** 2)\n",
    "                        # mask is the target circles\n",
    "                        mask=0.85*(D<0.5).float()+0.15*(D<1).float()\n",
    "\n",
    "\n",
    "\n",
    "                        loss= (0.9*mask-observations.states[-1,:,:,0]).pow(2).sum().sqrt()\n",
    "\n",
    "                        # optimisation step\n",
    "                        self.reach_goal_optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        self.reach_goal_optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "                        #compute again the kernels for the next step because parameters have been changed with the optimization\n",
    "                        self.system.lenia_step.compute_kernel()\n",
    "\n",
    "\n",
    "                        dead=observations.states[-1,:,:,0].sum()<10\n",
    "                        if(dead and last_dead):\n",
    "                          self.reach_goal_optimizer.zero_grad()\n",
    "                          break\n",
    "                        last_dead=dead\n",
    "\n",
    "                    ###### END of INNER loop #####\n",
    "\n",
    "\n",
    "                    # if not enough improvement at the first outer loop (just after random explo) then try another init\n",
    "                    if(len(self.policy_library) >= self.config.num_of_random_initialization and len(self.policy_library)-self.config.num_of_random_initialization<2 ):\n",
    "                      if(loss>19.5):\n",
    "                        break\n",
    "                      else:\n",
    "                        if(len(self.policy_library)-self.config.num_of_random_initialization==2):\n",
    "                          again=False\n",
    "\n",
    "                    # gather back the trained parameters\n",
    "                    self.system.update_initialization_parameters()\n",
    "                    self.system.update_update_rule_parameters()\n",
    "                    policy_parameters['initialization'] = self.system.initialization_parameters\n",
    "                    policy_parameters['update_rule'] = self.system.update_rule_parameters\n",
    "                    dist_to_target = loss.item()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "                ## look at the reached goal ##\n",
    "                reached_goal=torch.zeros(3).cpu()\n",
    "                with torch.no_grad():\n",
    "                  for i in range(20):\n",
    "                    self.system.random_obstacle(8)\n",
    "                    self.system.generate_init_state()\n",
    "                    observations = self.system.run()\n",
    "                    if(observations.states[-1,:,:,0].sum()<10):\n",
    "                      reached_goal[0]=10\n",
    "                      break\n",
    "                    reached_goal = reached_goal+self.goal_space.map(observations).cpu()/20\n",
    "                if(len(self.policy_library)-self.config.num_of_random_initialization>=2):\n",
    "                  print(\"reached= \"+str(reached_goal))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "            # save results\n",
    "            reached_goal=reached_goal.cpu()\n",
    "            self.db.add_run_data(id=run_idx,\n",
    "                                 policy_parameters=policy_parameters,\n",
    "                                 observations=observations,\n",
    "                                 source_policy_idx=source_policy_idx,\n",
    "                                 target_goal=target_goal,\n",
    "                                 reached_goal=reached_goal,\n",
    "                                 n_optim_steps_to_reach_goal=optim_step_idx,\n",
    "                                 dist_to_target=dist_to_target)\n",
    "\n",
    "            # add policy and reached goal into the libraries\n",
    "            # do it after the run data is saved to not save them if there is an error during the saving\n",
    "\n",
    "\n",
    "            self.policy_library.append(policy_parameters)\n",
    "            self.goal_library = torch.cat([self.goal_library, reached_goal.reshape(1, -1).to(self.goal_library.device).detach()])\n",
    "            if len(self.policy_library) >= self.config.num_of_random_initialization:\n",
    "              plt.imshow(self.system.init_wall.cpu())\n",
    "              plt.scatter(((self.goal_library[:,0]<0.11).float()*(self.goal_library[:,2]>-0.5).float()*(self.goal_library[:,2]+0.5)*self.system.config.SY).cpu(),((self.goal_library[:,0]<0.11).float()*(self.goal_library[:,1]>-0.5).float()*(self.goal_library[:,1]+0.5)*self.system.config.SX).cpu())\n",
    "              plt.show()\n",
    "            # increment run_idx\n",
    "\n",
    "\n",
    "            run_idx += 1\n",
    "            progress_bar.update(1)\n",
    "\n",
    "\n",
    "            #after the random explo if not enough living crea (even static ones)\n",
    "            if len(self.policy_library) == self.config.num_of_random_initialization:\n",
    "                if(nb_alive_random<2):\n",
    "                    break\n",
    "                print(run_idx)\n",
    "\n",
    "            if len(self.policy_library)==n_exploration_runs-1:\n",
    "                again=False\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IwbrnpC90bBj"
   },
   "source": [
    "## Run the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "XdVJ2aBJ5ze7",
    "outputId": "d3ba2166-a312-4bca-eac6-e611f997a533"
   },
   "outputs": [],
   "source": [
    "# Load System: here lenia\n",
    "lenia_config = Lenia_C.default_config()\n",
    "lenia_config.SX = 256\n",
    "lenia_config.SY = 256\n",
    "lenia_config.final_step = 50\n",
    "lenia_config.version = 'pytorch_fft'\n",
    "lenia_config.nb_kernels=10\n",
    "\n",
    "initialization_space_config = Dict()\n",
    "initialization_space = LeniaInitializationSpace(config=initialization_space_config)\n",
    "\n",
    "system = Lenia_C(initialization_space=initialization_space, config=lenia_config, device='cuda')\n",
    "\n",
    "# Load ExplorationDB\n",
    "db_config = ExplorationDB.default_config()\n",
    "db_config.db_directory = '.'\n",
    "db_config.save_observations = False\n",
    "db_config.keep_saved_runs_in_memory=False\n",
    "db_config.load_observations = True\n",
    "exploration_db = ExplorationDB(config=db_config)\n",
    "\n",
    "# Load Imgep Explorer\n",
    "\n",
    "\n",
    "output_representation_config = LeniaCentroidRepresentation.default_config()\n",
    "output_representation_config.env_size = (system.config.SX, system.config.SY)\n",
    "output_representation = LeniaCentroidRepresentation(config=output_representation_config)\n",
    "goal_space = BoxGoalSpace(output_representation)\n",
    "\n",
    "## Load Goal Space Representation\n",
    "\n",
    "# goal_space = BoxGoalSpace(output_representation,low=torch.tensor([0,-0.5,-0.5]),high=torch.tensor([2,0.5,0.5]),autoexpand=False)\n",
    "\n",
    "## Load imgep explorer\n",
    "explorer_config = IMGEPExplorer.default_config()\n",
    "explorer_config.num_of_random_initialization = 40\n",
    "explorer_config.reach_goal_optimizer = Dict()\n",
    "explorer_config.reach_goal_optimizer.optim_steps = 125\n",
    "explorer_config.reach_goal_optimizer.name = \"Adam\"\n",
    "explorer_config.reach_goal_optimizer.initialization_cppn.parameters.lr = 0.8e-2\n",
    "explorer_config.reach_goal_optimizer.lenia_step.parameters.lr = 0.8e-3\n",
    "explorer = IMGEPExplorer(system, exploration_db, goal_space, config=explorer_config)\n",
    "\n",
    "\n",
    "# Run Imgep Explorer\n",
    "explorer.run(160)\n",
    "\n",
    "# # save\n",
    "# explorer.save('explorer.pickle')\n",
    "#\n",
    "#restart from checkpoint\n",
    "# explorer = IMGEPExplorer.load('explorer.pickle', load_data=False, map_location='cpu')\n",
    "# explorer.db = ExplorationDB(config=db_config)\n",
    "# explorer.db.load(map_location='cpu')\n",
    "# explorer.run(20, continue_existing_run=True)\n",
    "\n",
    "\n",
    "goal_lib_copy=explorer.goal_library*1.0\n",
    "goal_lib_copy[:,2]=goal_lib_copy[:,2]+1000*(goal_lib_copy[:,1]<-8)+1000*(goal_lib_copy[:,0]>0.12)\n",
    "best_achiever=torch.argmin(goal_lib_copy[:,2])\n",
    "print(\"best achiever is run : \"+str(best_achiever))\n",
    "print(\"goal achieved by the best achiever :\" +str(explorer.goal_library[best_achiever]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urCZnX-rfW4q"
   },
   "source": [
    "## Try the best creature you obtained during the method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "54LI47CTfY6E",
    "outputId": "8680c300-33df-4065-caf7-a5bb03ae0738"
   },
   "outputs": [],
   "source": [
    "\n",
    "SY =  512#@param {type:\"integer\"}\n",
    "SX =  256#@param {type:\"integer\"}\n",
    "# timesteps =  200#@param {type:\"integer\"}\n",
    "mode = \"draw\" #@param [\"draw\", \"random\"]\n",
    "modeb = \"none\" #@param [\"growth\", \"sum\", \"none\", \"both\"]\n",
    "borders = False #@param {type:\"boolean\"}\n",
    "nb=best_achiever.cpu().numpy()\n",
    "if(nb<10):\n",
    "  creaFile=(\"run_000000\"+str(nb)+\"_data.pickle\")\n",
    "elif(nb<100):\n",
    "  creaFile=(\"run_00000\"+str(nb)+\"_data.pickle\")\n",
    "elif(nb<1000):\n",
    "  creaFile=(\"run_0000\"+str(nb)+\"_data.pickle\")\n",
    "else:\n",
    "  creaFile=(\"run_000\"+str(nb)+\"_data.pickle\")\n",
    "\n",
    "main(SX,SY,mode,borders,[0,1,2,3,4,5,6,7,8,9],creaFile=creaFile,modeb=modeb,zoom=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MY8RA95VuZtE"
   },
   "source": [
    "## save all\n",
    "\n",
    "Run this if you want to save every creature obtained during the training (at every IMGEP outer loop step). Then you just need to download data.zip.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iPpZz40vb2rk",
    "outputId": "8458cad6-f219-4eff-dfcc-749c5c5609a3"
   },
   "outputs": [],
   "source": [
    "print(\"best achiever is IMGEP step\" + str(best_achiever))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QXUsDAa3MH6P",
    "outputId": "e241e699-d10a-4753-8afc-4c27145a79a7"
   },
   "outputs": [],
   "source": [
    "!rm -r data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2mCnYXK_t1PA"
   },
   "outputs": [],
   "source": [
    "!mkdir data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5J02U7Edt4FC"
   },
   "outputs": [],
   "source": [
    "!mv run_*_data.pickle data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oQraEwEzuHUr",
    "outputId": "c22830c6-29c8-443d-b658-df080dfc4ee1"
   },
   "outputs": [],
   "source": [
    "!zip data.zip data/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WQPyONDC5P2e"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "47jvTfTT5QHx"
   },
   "source": [
    "# Gecko experiment (display of differentiable lenia)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-X1__sOf5QHy"
   },
   "source": [
    " Experiment and code for image import  from https://distill.pub/2020/growing-ca/ . In our case we'll only try to converge towards a black and white gecko. And we'll also optimize the initialization.\n",
    "\n",
    " It can be hard to converge toward the gecko shape with a single channel (but single channel is very fast). And as the initialization matters a lot you may have to run several seed until you get a nice convergence. (With a single channel the shape will be only vaguely a gecko)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 789
    },
    "id": "UX6WZu1V5QHz",
    "outputId": "7062eb56-8fed-4005-e18c-9083eff2e252"
   },
   "outputs": [],
   "source": [
    "#code from code for image import  from https://distill.pub/2020/growing-ca/\n",
    "\n",
    "import json\n",
    "import requests\n",
    "import PIL.Image, PIL.ImageDraw\n",
    "import io\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "TARGET_EMOJI = \"🦎\" #@param {type:\"string\"}\n",
    "\n",
    "\n",
    "\n",
    "from tensorflow.keras.layers import Conv2D\n",
    "\n",
    "def load_image(url, max_size=256):\n",
    "  r = requests.get(url)\n",
    "  img = PIL.Image.open(io.BytesIO(r.content))\n",
    "  img.thumbnail((max_size, max_size), PIL.Image.ANTIALIAS)\n",
    "  img = np.float32(img)/255.0\n",
    "  # premultiply RGB by Alpha\n",
    "  img[..., :3] *= img[..., 3:]\n",
    "  return img\n",
    "\n",
    "def load_emoji(emoji):\n",
    "  code = hex(ord(emoji))[2:].lower()\n",
    "  url = 'https://raw.githubusercontent.com/googlefonts/noto-emoji/main/png/128/emoji_u%s.png'%code\n",
    "  print(url)\n",
    "  return load_image(url)\n",
    "\n",
    "target_img = load_emoji(TARGET_EMOJI)\n",
    "def to_alpha(x):\n",
    "  return np.clip(x[..., 3:4], 0.0, 1.0)\n",
    "def to_rgb(x):\n",
    "  # assume rgb premultiplied by alpha\n",
    "  rgb, a = x[..., :3], to_alpha(x)\n",
    "  return 1.0-a+rgb\n",
    "def zoom(img, scale=4):\n",
    "  img = np.repeat(img, scale, 0)\n",
    "  img = np.repeat(img, scale, 1)\n",
    "  return img\n",
    "\n",
    "plt.imshow(to_rgb(target_img))\n",
    "plt.show()\n",
    "gray_target_img=np.dot(zoom(to_rgb(target_img),2), [0.2989, 0.5870, 0.1140])\n",
    "plt.imshow(1-gray_target_img,cmap='gray')\n",
    "plt.show()\n",
    "\n",
    "# cmap = cm.get_cmap('rainbow')\n",
    "# plt.imshow(cmap(1-gray_target_img))\n",
    "# plt.show()\n",
    "\n",
    "target_img=torch.tensor(1-gray_target_img)\n",
    "plt.imshow(target_img.cpu()[:,:])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "e2sjmJIi5QH1",
    "outputId": "7131eb3e-f543-4516-bacf-295200420c2a"
   },
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "\n",
    "C=1\n",
    "system=Lenia_C(nb_k=40,init_size=60,C=C,device='cuda')\n",
    "system.final_step=50\n",
    "system.generate_init_state()\n",
    "\n",
    "\n",
    "#loop to sample new parameters until we get rules which do not kill the creature\n",
    "with torch.no_grad():\n",
    "  dead=True\n",
    "  while dead:\n",
    "    system.reset()\n",
    "    observations=system.run()\n",
    "    dead=(observations.states[-1,:,:,0].sum()<400)\n",
    "    print(observations.states[-1,:,:,0].sum())\n",
    "  system.update_update_rule_parameters()\n",
    "  torch.save(system.update_rule_parameters, 'init.pickle')\n",
    "\n",
    "\n",
    "# optimizer=Adam(system.lenia_step.parameters(),lr=1e-3)\n",
    "optimizer=Adam([{'params': system.initialization.parameters(),\"lr\":8e-3},{'params': system.lenia_step.parameters(),'lr':1e-3}],lr=2e-3)\n",
    "loss_list=[]\n",
    "\n",
    "\n",
    "for training_step in range(601):\n",
    "          system.generate_init_state(X=85,Y=85)\n",
    "          observations = system.run()\n",
    "          if(observations.states[-1,:,:,0].sum()<300):\n",
    "            print(\"died\")\n",
    "            break\n",
    "          loss= (target_img[:,:]-observations.states[-1,:,:,0]).pow(2).sum().sqrt()\n",
    "          if training_step%40==0:\n",
    "            plt.imshow(observations.states[-1,:,:,0].detach().cpu().numpy())\n",
    "            plt.show()\n",
    "            with VideoWriter(\"out.mp4\", 30.0) as vid:\n",
    "                for timestep in range(observations[\"states\"].shape[0]):\n",
    "\n",
    "\n",
    "                  rgb_im=torch.clip(target_img[:,:]+observations.states[timestep,:,:,0],0,1).detach().cpu().numpy()\n",
    "\n",
    "                  vid.add(rgb_im)\n",
    "                vid.show()\n",
    "                  # print(system.lenia_step.h)\n",
    "\n",
    "          loss_list.append(loss.detach().cpu())\n",
    "          optimizer.zero_grad()\n",
    "          loss.backward()\n",
    "          optimizer.step()\n",
    "          old_loss = loss.item()\n",
    "          system.lenia_step.compute_kernel()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "uDjyEeN-qTwc",
    "xlygnkPVc8dV",
    "oimkkOjkpic2",
    "Teo-Z0yYZpVP",
    "8Bc3vjVL8BM2",
    "815hRpLz8Hm9"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
